‍

‍

# 概念

‍

## 零碎

‍

‍

### 为什么选择这个项目作为个人项目？

我的: EduEx

‍

#### 你的项目怎么只有一个?

错了, 其实是好几个. 我的EduExch是一个个人项目的大合集. 实际上至少包含了两个版本: 微服务以及单体版, 其中微服务是实习之后制作的, 修改了不少细节点.

单体还有一些造轮子的点. 他们都实现了良好的扩展性, 我可以将模块搬进来, 因此一年就做这两个实现即可.

其实我之前还在Github上面传了自己或团队一起实现的一些项目, 可以移步观赏.

> 之后确实需要再来个轮子啥的. 再来个实习项目就够了.

‍

‍

### 优化接口调用效率有什么思路？

* **缓存** ：使用缓存减少重复调用，提高响应速度。
* **异步调用** ：使用异步调用减少等待时间，提高并发性能。
* **批量处理** ：将多个请求合并为一个批量请求，减少网络开销。
* **负载均衡** ：使用负载均衡分配请求，避免单点瓶颈。
* **超时控制** ：设置合理的超时时间，避免长时间等待。
* **重试机制** ：在请求失败时进行重试，提高成功率。

‍

### OKR周报是什么(阿里内部管理 - 阿里钉)

确定目标 Objectives     确定KeyResult 关键结果    确定时间周期    确定责任人

‍

### 租户隔离一般是怎么做的

租户隔离是多租户系统中的一个关键概念，确保不同租户的数据和操作相互隔离。常见的租户隔离方法有以下几种：

1. **数据库级隔离**：

    * 每个租户使用独立的数据库。
    * 优点：隔离性强，安全性高。
    * 缺点：管理复杂，资源开销大。
2. **Schema级隔离**：

    * 每个租户使用同一个数据库中的不同 schema。
    * 优点：隔离性较强，管理相对简单。
    * 缺点：需要数据库支持 schema，复杂度介于数据库级和表级之间。
3. **表级隔离**：

    * 所有租户共享同一个数据库和 schema，但每个租户的数据存储在不同的表中。
    * 优点：管理简单，资源利用率高。
    * 缺点：隔离性较弱，表数量多时管理复杂。
4. **行级隔离**：

    * 所有租户共享同一个数据库和表，通过在表中添加租户标识（如 `tenant_id`​）来区分不同租户的数据。
    * 优点：资源利用率最高，管理最简单。
    * 缺点：隔离性最弱，需在应用层确保数据隔离。

‍

‍

### 二十个硬币两个人，轮流捡起来，每次可以捡1、2个，捡到第20个获胜，你怎么捡硬币保证获胜？

要保证获胜，你需要确保每次轮到对手时，剩下的硬币数量是3的倍数。这样无论对手捡1个还是2个，你都可以调整自己的策略，使得对手再次面对3的倍数的硬币。

具体策略如下：

1. 如果你是先手，第一次捡2个硬币，剩下18个。
2. 之后每次根据对手捡的数量，调整自己捡的数量，使得每次对手面对的硬币数量是3的倍数。

例如：

* 如果对手捡1个，你就捡2个。
* 如果对手捡2个，你就捡1个。

这样你就能保证在最后捡到第20个硬币。

‍

‍

## 如果有个场景下有个非常大的日志文件，好几个g，我要怎么查找到它的内容，是否出现了某一行？

处理非常大的日志文件时，可以使用以下几种方法来查找特定内容：

‍

### 1. 使用 `grep`​ 命令

​`grep`​ 是一个强大的命令行工具，可以快速搜索文件中的特定内容。

```sh
grep "要查找的内容" /path/to/large/logfile.log
```

### 2. 使用 `zgrep`​ 命令

如果日志文件是压缩的（如 `.gz`​ 文件），可以使用 `zgrep`​。

```sh
zgrep "要查找的内容" /path/to/large/logfile.log.gz
```

### 3. 使用 `awk`​ 命令

​`awk`​ 是一个强大的文本处理工具，可以用来搜索和处理大文件。

```sh
awk '/要查找的内容/' /path/to/large/logfile.log
```

‍

‍

‍

## 为什么很多工程师不喜欢 Java

啰嗦。在语言上比较繁琐以及架构上各种过度设计。

‍

## ​`while`​ 死循环中，如果你一直执行 `i++`​

在一个 `while`​ 死循环中，如果你一直执行 `i++`​，会导致以下情况：

1. **CPU 占用率高**：由于循环没有终止条件，CPU 会一直执行这个循环，导致 CPU 占用率非常高。
2. **内存泄漏**：如果在循环中有内存分配操作而没有适当的释放，会导致内存泄漏。
3. **整数溢出**：如果 `i`​ 是一个有限大小的整数类型（如 `int`​），当 `i`​ 增加到其最大值时，会发生整数溢出，`i`​ 会变为负数或从最小值重新开始。

以下是一个简单的示例：

```java
public class InfiniteLoop {
    public static void main(String[] args) {
        int i = 0;
        while (true) {
            i++;
            // 其他操作
        }
    }
}
```

在这个示例中，`i`​ 会不断增加，直到达到 `int`​ 的最大值 `2147483647`​，然后溢出变为 `-2147483648`​，继续增加。这个循环永远不会终止。

可以打条件端点来确认

‍

‍

## 假如给你一个新产品，你将从哪些方面来保障它的质量

‍

可以从代码开发、测试保障、线上质量三个方面来保障。

在代码开发阶段，有单元测试、代码Review、静态代码扫描等；

测试保障阶段，有功能测试、性能测试、高可用测试、稳定性测试、兼容性测试等；

在线上质量方面，有灰度发布、紧急回滚、故障演练、线上监控和巡检等。

‍

# 大块

‍

## 高并发、高可用问题 常用处理

‍

### 高并发

Key

1. 寻找性能瓶颈
2. 分治思想. 进行业务拆分，流程拆分
3. 扩容
4. 限流
5. 分流. 例如cdn 缓存
6. 流量清洗 waf
7. 多级缓存设计. 后端缓存，客户端缓存
8. 日志溯源
9. 资源隔离
10. 弹性扩缩容
11. 降级处理 前后端 兜底数据

‍

‍

### 高可用

1. 容器化管理 HA
2. keepalived

‍

‍

## 海量数据问题

‍

### **百万量级的数据排序：**

* **任意大小**：外排序，先将数据拆分到多个文件中，分别加载到内存中排序，然后再归并到一个文件里。实际上就是 [LeetCode 23. 合并 k 个有序链表](mweblib://15783856405435)，需要用到最小堆
* 范围为 [0, 10000]：**计数排序**

计数排序是一种适用于数据范围有限的排序算法。它通过计数每个元素出现的次数，然后根据计数结果将元素按顺序输出。

‍

计数排序实现

1. **创建计数数组**：大小为 `10001`​，用于记录每个元素出现的次数。
2. **计数元素**：遍历输入数组，记录每个元素的出现次数。
3. **输出排序结果**：根据计数数组输出排序后的结果。

‍

1. **计数数组**：`int[] count = new int[max + 1];`​ 创建一个大小为 `10001`​ 的计数数组。
2. **计数过程**：`for (int num : arr) { count[num]++; }`​ 遍历输入数组，记录每个元素的出现次数。
3. **输出排序结果**：`for (int i = 0; i <= max; i++) { while (count[i] > 0) { arr[index++] = i; count[i]--; } }`​ 根据计数数组输出排序后的结果。

‍

### **百万量级的数据查询在不在**

可以使用位图，前提是数据范围不超过内存大小。

位图（Bitmap）是一种高效的数据结构，用于表示大量的布尔值。对于百万量级的数据查询，可以使用位图来快速判断某个数据是否存在。以下是一个简单的 Java 实现，假设数据范围在 `[0, 1000000]`​ 之间。

‍

位图实现

1. **创建位图数组**：大小为 `1000001`​，每个元素表示一个布尔值。
2. **设置位图**：将存在的数据对应的位图位置设置为 `true`​。
3. **查询数据**：检查位图对应位置的值来判断数据是否存在。

```java
public class Bitmap {
    private boolean[] bitmap;

    public Bitmap(int size) {
        bitmap = new boolean[size];
    }

    // 设置位图
    public void set(int num) {
        bitmap[num] = true;
    }

    // 查询数据是否存在
    public boolean get(int num) {
        return bitmap[num];
    }

    public static void main(String[] args) {
        int size = 1000001;
        Bitmap bitmap = new Bitmap(size);

        // 示例数据
        int[] data = {5, 3, 2, 6, 8, 1, 0, 9, 7, 4};

        // 设置位图
        for (int num : data) {
            bitmap.set(num);
        }

        // 查询数据
        int query = 6;
        if (bitmap.get(query)) {
            System.out.println(query + " 存在");
        } else {
            System.out.println(query + " 不存在");
        }
    }
}
```

‍

1. **位图数组**：`private boolean[] bitmap;`​ 创建一个布尔数组表示位图。
2. **设置位图**：`public void set(int num) { bitmap[num] = true; }`​ 将存在的数据对应的位图位置设置为 `true`​。
3. **查询数据**：`public boolean get(int num) { return bitmap[num]; }`​ 检查位图对应位置的值来判断数据是否存在。

‍

‍

‍

‍

### **百万量级的数据求 TopK**：

数据流的 TopK 问题，维护一个大小为 k 的小根堆，然后分片读入数据，并更新堆。

‍

题目

假如有一个1G大小的文件，文件里每一行是一个词，每个词的大小不超过16byte，要求返回出现频率最高的100个词。内存大小限制是10M

‍

#### 解法一

这种解法的主要思路如下：

1. 采用分治的思想，进行哈希取余
2. 使用HashMap统计每个小文件单词出现的次数
3. 使用小顶堆，遍历步骤2中的小文件，找出词频top100的单词

‍

由于内存限制，我们无法直接将大文件的所有词一次性读到内存中。

可以采用分治策略，把一个大文件分解成多个小文件，保证每个文件的大小小于10M，进而直接将单个小文件读取到内存中进行处理。

第一步，首先遍历大文件，对遍历到的每个词x，执行 hash(x) % 500，将结果为i的词存放到文件f(i)中，遍历结束后，可以得到500个小文件，每个小文件的大小为2M左右；

第二步，接着统计每个小文件中出现频数最高的100个词。可以使用HashMap来实现，其中key为词，value为该词出现的频率。

对于遍历到的词x，如果在map中不存在，则执行 map.put(x, 1)。

若存在，则执行 map.put(x, map.get(x)+1)，将该词出现的次数加1。

第三步，在第二步中找出了每个文件出现频率最高的100个词之后，通过维护一个小顶堆来找出所有小文件中出现频率最高的100个词。

具体方法是，遍历第一个文件，把第一个文件中出现频率最高的100个词构建成一个小顶堆。

如果第一个文件中词的个数小于100，可以继续遍历第二个文件，直到构建好有100个结点的小顶堆为止。

继续遍历其他小文件，如果遍历到的词的出现次数大于堆顶上词的出现次数，可以用新遍历到的词替换堆顶的词，然后重新调整这个堆为小顶堆。

当遍历完所有小文件后，这个小顶堆中的词就是出现频率最高的100个词。

但是很容易可以发现问题，在第二步中，如果这个1G的大文件中有某个词词频过高，可能导致小文件大小超过10m。这种情况下该怎么处理呢？

接下来看另外一种解法

‍

‍

#### 解法二

第一步：使用多路归并排序对大文件进行排序，这样相同的单词肯定是紧挨着的

‍

多路归并排序对大文件进行排序的步骤如下：

① 将文件按照顺序切分成大小不超过2m的小文件，总共500个小文件

② 使用10MB内存分别对 500 个小文件中的单词进行排序

③ 使用一个大小为500大小的堆，对500个小文件进行多路排序，结果写到一个大文件中

‍

其中第三步，对500个小文件进行多路排序的思路如下：

* 初始化一个最小堆，大小就是有序小文件的个数500。堆中的每个节点存放每个有序小文件对应的输入流。
* 按照每个有序文件中的下一行数据对所有文件输入流进行排序，单词小的输入文件流放在堆顶。
* 拿出堆顶的输入流，并其下一行数据写入到最终排序的文件中，如果拿出来的输入流中还有数据的话，那么将这个输入流再一次添加到栈中。否则说明该文件输入流中没有数据了，那么可以关闭这个流。
* 循环这个过程，直到所有文件输入流都没有数据为止。

‍

第二步：

① 初始化一个100个节点的小顶堆，用于保存100个出现频率最多的单词

② 遍历整个文件，一个单词一个单词的从文件中取出来，并计数

③ 等到遍历的单词和上一个单词不同的话，那么上一个单词及其频率如果大于堆顶的词的频率，那么放在堆中，否则不放

最终，小顶堆中就是出现频率前100的单词了。

解法2相对解法1，更加严谨，如果某个词词频过高或者整个文件都是同一个词的话，解法1不适用。

‍

‍

### **海量数据，统计只出现一次的数字**：

(1) 位图法

如果题目给定数据大小范围是 0～10000，那么只需要申请一个 10000 比特的空间。即使是将所有的 int 整数表示出来，也只需要 `2^32`​ bit 空间，大约 512MB，这个空间并不大。

‍

(2) Hash 分治法

如果**数据量过大**，也可以先使用 hash 函数，将所有整数映射到 N 个文件中；然后在每个文件中使用 bitmap 或者 HashMap 去重，最后归并所有文件中只出现一次的结果。

因为使用了 hash 函数，可以保证相同的数字必定会分到同一个文件中。

‍

‍

## **分批处理大数据**

* **问题**：如何分批处理数据？
* 回答：一开始`COUNT`​总的条数，然后使用`LIMIT`​和`OFFSET`​进行分批查询。每个线程处理一个固定范围的数据，若范围内无数据则停止。
* 追问：若多线程分批查询过程中有数据插入或者删除，则数据缺漏，如何解决问题？
* 回答：维护事务。
* 追问：多线程共享事务存在问题，不合适，有其他方式吗？
* 回答：上锁，但是效率低下;
* 正解: 使用一种基于唯一标识符（如主键）的方案, 每个家伙都从变量中获取下一步要处理的对象范围, 然后自己去处理.

‍

‍

# 高级

‍

‍

‍

## 负载均衡哪几种

负载均衡可以分为多种类型，主要包括以下几种：

1. **DNS负载均衡**：

    * 通过DNS服务器将流量分配到不同的服务器上。
    * 优点：简单易用，适用于全球分布的服务。
    * 缺点：DNS缓存可能导致负载不均衡。
2. **HTTP/HTTPS负载均衡**：

    * 在应用层（第7层）进行负载均衡，基于HTTP/HTTPS协议。
    * 优点：可以根据URL、Cookie、Header等进行智能路由。
    * 缺点：处理复杂，性能开销较大。
3. **TCP负载均衡**：

    * 在传输层（第4层）进行负载均衡，基于TCP协议。
    * 优点：性能较高，适用于大多数应用。
    * 缺点：无法进行应用层的智能路由。
4. **UDP负载均衡**：

    * 在传输层（第4层）进行负载均衡，基于UDP协议。
    * 优点：适用于实时应用，如视频流、在线游戏。
    * 缺点：不可靠传输，需应用层处理重传和错误。
5. **IP负载均衡**：

    * 在网络层（第3层）进行负载均衡，基于IP协议。
    * 优点：简单高效，适用于内部网络。
    * 缺点：无法进行传输层和应用层的智能路由。
6. **前端负载均衡**：

    * 主要用于分配用户请求到不同的前端服务器。
    * 优点：减轻单个前端服务器的压力，提高响应速度。
    * 缺点：需要额外的硬件或软件支持。
7. **后端负载均衡**：

    * 主要用于分配前端服务器的请求到不同的后端服务器（如应用服务器、数据库服务器）。
    * 优点：提高后端服务器的处理能力和可靠性。
    * 缺点：需要复杂的配置和管理。
8. **全局负载均衡**：

    * 在全球范围内分配流量到不同的地理位置的服务器。
    * 优点：提高全球用户的访问速度和可靠性。
    * 缺点：需要复杂的配置和管理。

每种负载均衡方式都有其适用的场景和优缺点，选择合适的负载均衡方式可以提高系统的性能和可靠性。

‍

---

JavaWeb角度(待补充)

从JavaWeb的角度来看，从一次请求到后端数据库的过程涉及多个层次的负载均衡。以下是每个层次的负载均衡示例：

1. **浏览器层**：

    * 浏览器通过DNS负载均衡将请求发送到不同的服务器。
    * 例如，浏览器请求`www.example.com`​，DNS服务器将其解析为多个IP地址，并将请求分配到不同的服务器。
2. **操作系统层**：

    * 操作系统可以使用IP负载均衡，将流量分配到不同的网络接口或服务器。
    * 例如，Linux操作系统可以使用`ipvsadm`​工具进行IP负载均衡。
3. **前端服务器层**：

    * 前端服务器（如Nginx或Apache）使用HTTP/HTTPS负载均衡，将请求分配到不同的应用服务器。
    * 例如，Nginx配置文件中的负载均衡配置：

    ```nginx
    http {
        upstream backend {
            server backend1.example.com;
            server backend2.example.com;
        }

        server {
            listen 80;
            location / {
                proxy_pass http://backend;
            }
        }
    }
    ```
4. **应用服务器层**：

    * 应用服务器（如Tomcat）使用TCP负载均衡，将请求分配到不同的服务实例。
    * 例如，使用HAProxy进行TCP负载均衡：

    ```haproxy
    frontend http-in
        bind *:80
        default_backend servers

    backend servers
        balance roundrobin
        server server1 192.168.1.1:8080 check
        server server2 192.168.1.2:8080 check
    ```
5. **数据库层**：

    * 数据库层使用后端负载均衡，将查询分配到不同的数据库实例。
    * 例如，使用MySQL的主从复制和读写分离进行负载均衡：

    ```sql
    -- 主数据库配置
    [mysqld]
    server-id=1
    log-bin=mysql-bin

    -- 从数据库配置
    [mysqld]
    server-id=2
    replicate-do-db=exampledb
    ```

通过在每个层次进行负载均衡，可以提高系统的性能和可靠性，确保请求能够高效地处理并返回结果。

‍

‍

## 设计一个高并发系统

‍

假设你在某知名电商公司干过高并发系统，用户上亿，一天流量几十亿，高峰期并发量上万，甚至是十万。那么人家一定会仔细盘问你的系统架构

你们系统啥架构？怎么部署的？部署了多少台机器？缓存咋用的？MQ咋用的？数据库咋用的？

‍

因为真正干过高并发的人一定知道，**脱离了业务的系统架构**都是在纸上谈兵，真正在复杂业务场景而且还高并发的时候，那系统架构一定不是那么简单的，用个redis，用mq就能搞定？当然不是，真实的系统架构搭配上业务之后，会比这种简单的所谓“高并发架构”要复杂很多倍。

‍

> 系统熔断、降级、限流

‍

其实所谓的高并发，如果你要理解这个问题呢，其实就得从高并发的根源出发，为啥会有高并发？

‍

刚开始系统都是连接数据库的，但是要知道数据库支撑到每秒并发两三千的时候，基本就快完了。所以才有说，很多公司，刚开始干的时候，技术比较low，结果业务发展太快，有的时候系统扛不住压力就挂了。

‍

* ==系统拆分==，将一个系统拆分为多个子系统，用dubbo来搞。然后**每个系统连一个数据库**，这样本来就一个库，现在多个数据库，不也可以抗高并发么。
* ==缓存，必须得用缓存==。大部分的高并发场景，都是**读多写少**，那你完全可以在数据库和缓存里都写一份，然后读的时候大量走缓存不就得了。毕竟人家redis轻轻松松单机几万的并发啊。没问题的。所以你可以考虑考虑你的项目里，那些承载主要请求的读场景，怎么用缓存来抗高并发。
* ==MQ，必须得用MQ==。可能你还是会出现**高并发写**的场景. 用redis来承载写那肯定不行，人家是缓存，数据随时就被LRU了，数据格式还无比简单，没有事务支持。所以该用mysql还得用mysql啊。

  用MQ吧，大量的写请求灌入MQ里，排队慢慢玩儿，后边系统消费后慢慢写，控制在mysql承载范围之内。所以你得考虑考虑你的项目里，那些承载复杂写业务逻辑的场景里，如何用MQ来异步写，提升并发性。MQ单机抗几万并发也是ok的，这个之前还特意说过。
* ==分库分表==，可能到了最后**数据库层面**还是免不了抗高并发的要求

  就将一个数据库拆分为多个库，多个库来抗更高的并发；然后将一个表拆分为多个表，每个表的数据量保持少一点，提高sql跑的性能。
* ==读写分离==，这个就是说大部分时候数据库可能也是读多写少，没必要所有请求都集中在一个库上吧，可以搞个主从架构，主库写入，从库读取，搞一个读写分离。读流量太多的时候，还可以加更多的从库。
* ==Elasticsearch==，可以考虑用es。es是**分布式**的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来抗更高的并发。那么一些比较简单的**查询、统计类**的操作，可以考虑用es来承载，还有一些全文搜索类的操作，也可以考虑用es来承载

‍

‍

‍

## 设计一个秒杀系统

> 这个是完整实现, 具体答Redis也可

‍

‍

### 难点

最大的问题在于容易产生大并发请求、产生超卖现象和性能问题

‍

1）瞬时大并发：一提到秒杀系统给人最深刻的印象是超大的瞬时并发，这时你可以联想到小米手机的抢购场景，在小米手机抢购的场景一般都会有10w＋的用户同时访问一个商品页面去抢购手机，这就是一个典型的**瞬时大并发**，如果系统没有经过限流或者熔断处理，那么系统瞬间就会崩掉，就好像被DDos攻击一样；

2）超卖：秒杀除了大并发这样的难点，还有一个所有电商都会遇到的痛，那就是超卖，电商搞大促最怕什么？最怕的就是超卖，产生超卖了以后会影响到用户体验，会导致订单系统、库存系统、供应链等等，产生的问题是一系列的连锁反应，所以电商都不希望超卖发生，但是在大并发的场景最容易发生的就是超卖，不同线程读取到的当前库存数据可能下个毫秒就被其他线程修改了，如果没有一定的锁库存机制那么库存数据必然出错，都不用上万并发，几十并发就可以导致商品超卖；

3）性能：当遇到大并发和超卖问题后，必然会引出另一个问题，那就是性能问题，如何保证在大并发请求下，系统能够有好的性能，让用户能够有更好的体验，不然每个用户都等几十秒才能知道结果，那体验必然是很糟糕的；

4）黄牛：你这么低的价格，假如我抢到了，我转手卖掉我不是**血赚**？就算我不卖我也不亏啊，那用户知道，你知道，别的别有用心的人（黑客、黄牛…）肯定也知道的。

那简单啊，我知道你什么时候抢，我搞个几十台机器搞点脚本，我也模拟出来十几万个人左右的请求，那我是不是意味着我基本上有80%的成功率了。

5）F12链接提前暴露, 没做好隐藏

‍

‍

### 要点

1）对于大秒杀活动，一般运营会配置**静态的活动页面**，配置静态活动页面主要有两个目的一方面是为了便于在各种社交媒体**分发**，另一方面是因为秒杀**活动页的流量**是大促期间最大的，通过配置成静态页面可以将页面发布在公有云上动态的横向扩展；

2）将秒杀活动的静态页面提前刷新到**CDN节点**，通过CDN节点的页面缓存来缓解访问压力和公司网络带宽，CDN上缓存js、css和图片；或者Nginx服务器提供的静态资源功能。

3）将秒杀服务部署在公有云的web server上，使用公有云最大的好处就是能够根据活动的火爆程度**动态扩容**而且成本较低，同时将访问压力隔离在公司系统外部；

4）在提供真正商品秒杀业务功能的app server上，需要进行交易限流、熔断控制，防止因为秒杀交易影响到其他正常服务的提供。

5）服务降级处理，除了上面讲到的限流和熔断控制，我们还设定了**降级开关**，对于首页、购物车、订单查询、大数据等功能都会进行一定程度的服务降级。比如进行秒杀的时候，将订单查询系统进行降级，减少秒杀压力

6）如何防止超卖现象的发生，我们日常的下单过程中防止超卖一般是通过在**数据库上加锁**来实现。但是还是无法满足秒杀的上万并发需求，我们的方案其实也很简单: **实时库存的扣减在缓存中进行**，异步扣减数据库中的库存，保证缓存中和数据库中库存的**最终一致性**。

7）库存预热：那不简单了，我们要开始秒杀前你通过**定时任务**或者运维同学**提前把商品的库存加载到Redis中**去，让整个流程都在Redis里面去做，然后等秒杀介绍了，再异步的去修改库存就好了

8）MQ削峰填谷

‍

你可以把它放消息队列，然后一点点消费去改库存就好了嘛，不过单个商品其实一次修改就够了，我这里说的是**某个点多个商品**一起秒杀的场景，像极了双十一零点。

1. 使用缓存。
2. 页面静态化技术。
3. 数据库优化。
4. 分类数据库中活跃的数据。
5. 批量读取和延迟修改。
6. 读写分离。

‍

‍

## 解决高并发秒杀的超卖问题

‍

**由秒杀引发的一个问题**

* 秒杀最大的一个问题就是解决超卖的问题。**其中一种解决超卖如下方式：**

```text
1 update goods set num = num - 1 WHERE id = 1001 and num > 0
```

我们假设现在商品只剩下一件了，此时数据库中 **num =**  **1；**

但有100个线程同时读取到了这个 **num =**  **1**，所以100个线程都开始减库存了。

但你会最终会发觉，**其实只有一个线程减库存成功，其他99个线程全部失败。**

---

**这就是MySQL中的排他锁起了作用。**

排他锁又称为写锁，简称X锁，顾名思义，排他锁就是不能与其他所并存，**如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁**，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。

‍

就是类似于我在执行update操作的时候，这一行是一个事务 **(默认加了排他锁**)。**这一行不能被任何其他线程修改和读写**

‍

* **第二种解决超卖的方式如下**

```text
1 select version from goods WHERE id= 1001
2 update goods set num = num - 1, version = version + 1 WHERE id= 1001 AND num > 0 AND version = @version(上面查到的version);
```

这种方式采用了**版本号**的方式，其实也就是**CAS**的原理。

假设此时version = 100， num = 1; 100个线程进入到了这里，同时他们select出来版本号都是version = 100。

然后直接update的时候，只有其中一个先update了，同时更新了版本号。

那么其他99个在更新的时候，会发觉version并不等于上次select的version，就说明version被其他线程修改过了。那么我就放弃这次update

‍

* **第三种解决超卖的方式如下**

利用redis的单线程预减库存。比如商品有100件。那么我在redis存储一个k,v。例如 <gs1001, 100>

每一个用户线程进来，key值就减1，等减到0的时候，全部拒绝剩下的请求。

那么也就是只有100个线程会进入到后续操作。所以一定不会出现超卖的现象

‍

* 总结

可见第二种CAS是失败重试，并无加锁。比第一种加锁效率要高很多。**类似于Java中的Synchronize和CAS**

‍

‍

‍

## 如果同时有很多人扫罚款模块的支付码，安全问题怎么解决。

可以的方案

1. **使用HTTPS等好的通信手段**：确保所有的支付请求都通过HTTPS进行传输，防止数据在传输过程中被窃取或篡改。
2. **支付令牌**：每次生成唯一的支付令牌（token），并且令牌只能使用一次，防止重复支付。(合适, 直接用token就行)
3. **限流**：对支付请求进行限流，防止恶意请求导致系统过载。(必须)
4. **身份验证**：在支付前进行用户身份验证，确保支付请求是由合法用户发起的。(必须)
5. **日志记录**：记录所有支付请求的日志，便于后续审计和追踪。(托底)

‍

## 如果第一次提交文件至云存储超时，不知道是否保存成功。第二次执行相同操作会执行成功吗

1. **幂等性**：确保文件上传操作是幂等的，即多次执行相同的操作不会导致副作用
2. 业务 - **检查文件存在性**：在第二次执行上传操作前，先检查文件是否已经存在于云存储中。如果存在，则不再重复上传
3. **重试机制**：实现上传操作的重试机制，在第一次上传失败后，自动重试上传操作。

实际上需要从多个角度分析超时, 究竟是在哪一个环境超时了? 比如云服务提供商那边的问题还是我们的开发的业务的问题, 还是用户的网络连接问题, 都会影响判断.

真正的情况还是需要具体问题具体分析

‍

‍

‍

### 现有一批邮件需要发送给订阅顾客，且有一个集群（集群的节点数不定，会动态扩容缩容）来负责具体的邮件发送任务，如何让系统尽快地完成发送？

‍

A. 借助消息中间件，通过发布者订阅者模式来进行任务分配  
B. master-slave 部署，由 master 来分配任务  
C. 不借助任何中间件，且所有节点均等。通过数据库的 update-returning，从而实现节点之间任务的互斥

‍

‍

## 秒杀系统综合

‍

### 业务上适当规避

1. 根据某些规则对部分用户直接返回没抢到。比如有些用户曾经被系统识别为恶意用户、垃圾用户、僵尸用户，直接告诉用户已经抢完
2. (我的主管说的), 直接按照手机尾号的数字规律, 取目标生成率的对应的尾号概率, 只让这部分人去进行操作, 其他的全部走. 随机数实际上不会对大伙都生效, 只有特定手机尾号的家伙才能进来.
3. 分散不同客户端打开活动入口的时间。比如将 1 秒内的流量分散到 10 秒

‍

### 技术上硬核抗压

1. 限流策略。比如在压力测试中我们测到系统 QPS 达到了极限，那么超过的部分直接返回已经抢完，通过 Nginx 的 lua 脚本可以查 redis 看到 QPS 数据从而可以动态调节
2. 异步削峰。对 Redis 中的红包预减数量，立即返回抢红包成功请用户等待，然后把发送消息发给消息队列，进行流量的第二次削峰，让后台服务慢慢处理
3. 服务逻辑。比如业务逻辑是使用事务控制对数据库的创建订单记录，减库存的操作，那么创建操作要放到减库存操作之前，从而避免减数量 update 的行锁持有时间
4. 机器配置。当然是服务器机器配置越高越好，数据库配置越猛越好，高并发抢红包主要是 CPU 与网络 IO 的负载较高，要选择偏向 CPU 与网络 IO 性能的机器

‍

‍

### 架构和实现细节

* 前端模块（页面静态化、CDN、客户端缓存）
* 排队模块（Redis、队列实现异步下单）
* 服务模块（事务处理业务逻辑、避免并发问题）
* 防刷模块（验证码、限制用户频繁访问）

‍

‍

### 模块解析

‍

#### 前端模块

1. 页面静态化，将后台渲染模板的方式改成使用 HTML 文件与 AJAX 异步请求的方式，减少服务端渲染开销，同时将秒杀页面提前放到 CDN
2. 客户端缓存，配置 Cache-Control 来让客户端缓存一定时间页面，提升用户体验
3. 静态资源优化，CSS/JS/图片压缩，提升用户体验

‍

#### 排队模块

1. 对 Redis 中的抢购对象预减库存，然后立即返回抢购成功请用户等待，这里利用了 Redis 将大部分请求拦截住，少部分流量进入下一阶段
2. 如果参与秒杀的商品太多，进入下一阶段的流量依然比较大，则需要使用消息队列，Redis 过滤之后的请求直接放入到消息队列，让消息队列进行流量的第二次削峰

‍

#### 服务模块

1. 消息队列的消费者，业务逻辑是使用事务控制对数据库的下订单，减库存操作，且下订单操作要放到减库存操作之前，可以避免减库存 update 的行锁持有时间

‍

#### 防刷模块

1. 针对恶意用户写脚本去刷，在 Redis 中保存用户 IP 与商品 ID 进行限制
2. 针对普通用户疯狂的点击，使用 JS 控制抢购按钮，每几秒才能点击一次
3. 在后台生成数学计算型的验证码，使用 Graphics、BufferedImage 实现图片，ScriptEngineManager 计算表达式

‍

#### 异常流程的处理

1. 如果在秒杀的过程中由于服务崩溃导致秒杀活动中断，那么没有好的办法，只能立即尝试恢复崩溃服务或者申请另寻时间重新进行秒杀活动
2. 如果在下订单的过程中由于用户的某些限制导致下单失败，那么应该回滚事务，立即告诉用户失败原因

‍

‍

### 总结

‍

#### 原则

业务优化思路：业务上适当规避  
技术优化思路：尽量将请求拦截在数据库的上游，因为一旦大量请求进入数据库，性能会急剧下降  
架构原则：合适、简单、演化（以上内容是最终版本，初版可以说没有用到队列，直接使用缓存-数据库这样的架构）

‍

#### 难点

1. 如何将高并发大流量一步步从业务和技术方面有条不紊地应对过来
2. 如何在代码中处理好异常情况以及应急预案的准备

‍

#### 坑

1. 以上的解决方案能通过利用 Redis 与消息队列集群来承载非常高的并发量，但是运维成本高。比如 Redis 与消息队列都必须用到集群才能保证稳定性，会导致运维成本太高。所以需要有专业的运维团队维护。
2. 避免同一用户同时下多个订单，需要写好业务逻辑或在订单表中加上**用户 ID 与商品 ID 的唯一索引**；避免超卖问题，在更新数量的 sql 上需要加上>0 条件 (CAS)

‍

#### 优化

1. 将 7 层负载均衡 Nginx 与 4 层负载均衡 LVS 一起使用进一步提高并发量
2. 以上是应用架构上的优化，在部署的 Redis、消息队列、数据库、虚拟机偏向选择带宽与硬盘读写速度高的
3. 提前预热，将最新的静态资源同步更新到 CDN 的所有节点上，在 Redis 中提前加载好需要售卖的产品信息
4. 使用分布式限流减少 Redis 访问压力，在 Nginx 中配置并发连接数与速度限制

‍

## 抢红包系统

总共有10亿个红包，在某个时间一起来抢红包，如何设计

‍

主要考察的是如何设计高并发系统，但实际上存在一定变通处理方式，不一定全在技术上

通常在考虑系统QPS时，应当按业务上的极限QPS作为系统必须承担的QPS设计，比如10亿个红包，因为用户量巨大，极限QPS是可能是10亿

但是一般来说几万QPS已经是比较高的并发了，就需要比较大的集群和高并发架构来处理了，所以不可能真正实现10亿的并发架构，而是通过一些变通的方法来处理，比如在业务上做一些处理规避掉部分流量

但尽可能地需要实现高并发架构，思路是将大部分流量拦截在系统承载能力低的模块之前

---

#### 业务上适当规避

在相应法律法规、规章制度、活动说明、用户体验允许的情况下，可以做以下处理

1. 根据某些规则对部分用户直接返回没抢到。比如有些用户曾经被系统识别为恶意用户、垃圾用户、僵尸用户，直接告诉用户已经抢完
2. 分散不同客户端打开活动入口的时间。比如将1秒内的10亿流量分散到10秒，那么平均每秒只有1亿了
3. 增加客户端入口点击门槛。比如需要手机摇一摇、画一个图案才能触发抢红包的接口

#### 技术上硬核抗压

网关是会接触实打实10亿流量的地方，也是拦截掉最多无效流量的地方，同理，缓存也是

1. 限流策略。比如在压力测试中我们测到系统1亿QPS达到了极限，那么超过的部分直接返回已经抢完，通过Nginx的lua脚本可以查redis看到QPS数据从而可以动态调节
2. 作弊拦截。通过对UA、IP规则直接将抢红包的作弊流量拦截掉
3. 异步削峰。对Redis中的红包预减数量，立即返回抢红包成功请用户等待，然后把发送消息发给消息队列，进行流量的第二次削峰，让后台服务慢慢处理
4. 服务逻辑。比如业务逻辑是使用事务控制对数据库的创建红包记录，减红包数量的操作，那么创建操作要放到减数量操作之前，从而避免减数量update的行锁持有时间
5. 机器配置。当然是服务器机器配置约高越好，数据库配置越猛越好，高并发抢红包主要是CPU的负载较高，要选择偏向CPU性能的机器
