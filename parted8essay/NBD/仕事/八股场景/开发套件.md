‍

‍

# <span data-type="text" style="color: var(--b3-font-color6);">JWT</span>

‍

‍

## 参数是什么样的?

JWT（JSON Web Token）由三个部分组成：Header、Payload 和 Signature。每个部分用点（.）分隔

‍

### **Header**:头

* **alg**: 指定签名算法，例如 HMAC SHA256 或 RSA。
* **typ**: 通常是 "JWT"，表示令牌类型。

示例：

```json
{
  "alg": "HS256",
  "typ": "JWT"
}
```

‍

‍

### **Payload**:负载

包含声明（claims），即关于实体（通常是用户）和其他数据的声明

‍

声明分为三类：

* **Registered claims**: 预定义的声明，如 `iss`​（发行者）、`exp`​（过期时间）、`sub`​（主题）、`aud`​（受众）等。
* **Public claims**: 可以自定义的声明，但应避免冲突。
* **Private claims**: 自定义声明，通常在不同方之间共享信息时使用。

‍

```json
{
  "sub": "1234567890",
  "name": "John Doe",
  "admin": true
}
```

‍

‍

### **Signature**:签名

用于验证消息的发送者和确保消息在传输过程中未被篡改

签名是通过对 Header 和 Payload 进行编码后，再使用指定的算法和密钥进行签名生成的。

‍

生成签名的伪代码：

```
HMACSHA256(
  base64UrlEncode(header) + "." +
  base64UrlEncode(payload),
  secret
)
```

‍

完整的 JWT 令牌示例：

```
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c
```

‍

每个部分的意义：

* **Header**: 指定令牌的元数据和签名算法。
* **Payload**: 包含实际的声明数据。
* **Signature**: 确保数据的完整性和真实性。

‍

‍

## 密文密码能被存入负载中吗？为什么？

不能, 应该是userId和其他信息存入, 这样调用时候在服务器找

‍

1. **安全性**：JWT的负载部分是经过Base64Url**编码**的，**但并没有加密**。这意味着任何拥有JWT的人都**可以解码并读取负载**中的内容。如果将密文密码存入负载中，攻击者可以轻易获取这些信息。
2. **数据泄露风险**：即使是加密后的密码，如果被存储在JWT的负载中，一旦JWT被截获，攻击者可以尝试对加密的密码进行**暴力破解**或其他攻击手段，从而获取原始密码。
3. **最佳实践**：通常，JWT的负载部分应只包含**非敏感信息**，如用户ID、角色等。敏感信息应存储在服务器端，并通过安全的方式进行访问和传输。

因此，密文密码不应被存入JWT的负载中。相反，建议将敏感信息存储在服务器端，并通过安全的API进行访问。

‍

‍

‍

## 使用(我的)Session+Redis替代JWT令牌进行登录模块的搭建相比有什么好处

* 普通token作为登录凭证可以主动续约，主动让token失效，用jwt有主动续约问题
* 能够自己方便的设计续约的功能
* jwt的信息是**存在header**里面的，可以从带宽层面聊聊（数据量大的时候）
* session机制**有状态**，服务端可以方便地管理多个客户端的会话，结合redis利用token可以实现**分布式环境**下的session会话管理；jwt机制无状态且自包含，服务端不需要额外的会话管理逻辑(或者通过黑名单机制和刷新机制实现类似于session的功能，但会引入复杂性)
* jwt是有个解码的过程，会增加服务端的损耗

‍

‍

## 服务端不能让jwt主动失效解决

redis白名单可以，把jwt存到自己失效为止. 或者加个标记失效时间的字段

‍

‍

# TL

‍

‍

## 为什么要用这个

​`ThreadLocal`​ 用于在每个线程中存储独立的变量副本。它的主要作用是为每个线程提供独立的变量副本，避免多线程环境下的变量共享问题

‍

### 作用

1. **线程隔离**：每个线程都有自己的变量副本，互不干扰。
2. **简化代码**：避免显式传递上下文信息，简化代码逻辑。
3. **提高性能**：减少锁的使用，提升并发性能。

‍

### 在项目中记录用户信息的原因

1. **线程安全**：在多线程环境下，每个线程都有独立的用户信息副本，避免了并发访问问题。
2. **上下文传递**：在处理用户请求时，可以方便地在不同方法和类之间传递用户信息，而不需要显式传递参数。

‍

‍

## 底层原理

​`ThreadLocal`​ 的底层实现依赖于每个线程内部维护的一个 `ThreadLocalMap`​ 对象

每个 `ThreadLocal`​ 对象在当前线程中都有一个独立的 `ThreadLocalMap`​ 实例，用于存储变量副本

​`ThreadLocalMap`​ 是一个自定义的哈希表，键是 `ThreadLocal`​ 对象，值是线程的变量副本

​`ThreadLocal`​ 实现了线程隔离，确保每个线程都有独立的变量副本

‍

```java
static class ThreadLocalMap {
    static class Entry extends WeakReference<ThreadLocal<?>> {
        Object value;
        Entry(ThreadLocal<?> k, Object v) {
            super(k);
            value = v;
        }
    }

    private Entry[] table;
    // 其他实现细节...
}
```

‍

‍

### 主要方法

1. **set(T value)** ：将当前线程的 `ThreadLocalMap`​ 中的变量设置为指定值
2. **get()** ：获取当前线程的 `ThreadLocalMap`​ 中的变量值
3. **remove()** ：移除当前线程的 `ThreadLocalMap`​ 中的变量

‍

‍

‍

## 你说的这个线程是什么玩意, 用户请求的线程还是啥?

在基于Servlet的Web应用中，每个HTTP请求都会由一个独立的线程来处理。ThreadLocal可以在这些线程中存储与当前请求相关的上下文信息（如用户信息），确保线程安全。

在Java Web应用中，用户请求线程通常由Web服务器（如Tomcat、Jetty等）管理。每个HTTP请求都会由一个独立的线程来处理

过滤器, Servlet, Controller等都可以:

‍

‍

## 可能会造成内存泄漏原因

‍

1. **键的弱引用**：`ThreadLocalMap`​ 中的键（`ThreadLocal`​ 对象）是使用弱引用（WeakReference）来存储的。这意味着当 `ThreadLocal`​ 对象没有其他强引用时，垃圾回收器可以回收它。
2. **值的强引用**：虽然键是弱引用，但值是强引用。如果 `ThreadLocal`​ 对象被回收，而线程仍然存活，`ThreadLocalMap`​ 中的值不会被自动清除，导致内存泄漏。
3. **线程池**：在使用线程池时，线程不会立即销毁，而是被重用。如果 `ThreadLocal`​ 没有显式地移除（调用 `remove()`​ 方法），可能会导致内存泄漏。

‍

### 预防措施

1. **显式移除**：在使用完 `ThreadLocal`​ 后，显式调用 `remove()`​ 方法清除数据。
2. **尽量避免长生命周期的** **​`ThreadLocal`​**​：避免在长生命周期的线程（如**线程池中的线程**）中使用 `ThreadLocal`​。

‍

‍

### Threadlocal执行remove（）方法可以解决泄露，但如果程序出异常了，remove执行不到，咋办

‍

#### 使用 try-finally 确保资源清理

通过在业务逻辑的 try 块中设置 ThreadLocal 数据，并在 finally 块中调用 `remove()`​ 方法，无论是否发生异常

```java
// 定义一个 ThreadLocal 变量
private static final ThreadLocal<MyContext> contextHolder = new ThreadLocal<>();

public void process() {
    try {
        // 先给 ThreadLocal 设置数据
        contextHolder.set(new MyContext());
        
        // 执行业务逻辑，可能会抛出异常
        doBusinessLogic();
        
    } finally {
        // 无论是否发生异常，这里都会执行
        contextHolder.remove();
    }
}

```

‍

‍

#### 封装调用逻辑，自动管理 ThreadLocal 生命周期

为了防止在每个需要使用 ThreadLocal 的方法中都遗漏 `remove()`​调用，可以将业务逻辑封装在一个辅助类或者工具方法中，将 ThreadLocal 的设置、业务运行以及清理统一做掉

```java
public class ThreadLocalUtil {

    public static void executeInContext(Consumer<MyContext> consumer) {
        // 初始化 ThreadLocal 数据
        MyContext context = new MyContext();
        contextHolder.set(context);
        try {
            consumer.accept(context);
        } finally {
            // 确保清理 ThreadLocal
            contextHolder.remove();
        }
    }
}

```

‍

业务逻辑调用时：

```
ThreadLocalUtil.executeInContext(context -> {
    // 这里放需要执行的业务逻辑
    doSomething(context);
});
```

‍

#### 其他

* **使用规范的设计模式、框架**：很多框架（如 Spring）在设计中已经考虑了 ThreadLocal 的使用场景。例如 Spring MVC 中的 RequestContextFilter 就会在请求结束后进行相应的清理。尽量利用这些已经成熟的解决方案可以降低出错概率。
* **线程池中的特殊注意**：如果使用的是线程池，线程不会结束，只会在任务之间复用。务必确保每个任务执行完毕后都能清理掉 ThreadLocal 中的内容，防止前一个任务的遗留数据影响后续任务。
* **日志与监控**：在关键业务中，可以使用日志记录 ThreadLocal 的生命周期，或者结合监控工具追踪可能的内存泄露风险，这样在出现问题时能更容易定位问题。

‍

# Websocket

‍

## 作用以及为什么用

作用

1. **实时通信**：WebSocket提供了全双工通信通道，允许客户端和服务器之间实时交换数据。这对于聊天室这种需要即时消息传递的应用非常重要。
2. **低延迟**：WebSocket连接一旦建立，数据可以在客户端和服务器之间低延迟地传输，避免了HTTP轮询带来的延迟和开销。
3. **高效性**：WebSocket连接是持久的，减少了频繁建立和关闭连接的开销，提升了通信效率。

‍

业务中使用, 聊天室这样的

1. **消息广播**：WebSocket可以将一条消息广播给所有连接的客户端，实现多人实时聊天。
2. **状态同步**：可以实时同步用户的在线状态、消息已读状态等。
3. **互动性**：支持实时互动，如用户输入提示、消息撤回等功能。

‍

‍

## 底层原理

‍

握手- 全双工 -传输帧 -连接

1. **握手过程**：WebSocket连接从HTTP协议开始，通过一个特殊的HTTP请求进行握手。服务器接受握手请求后，升级协议为WebSocket。
2. **全双工通信**：握手成功后，客户端和服务器之间建立一个全双工通信通道，允许双方随时发送和接收数据。
3. **数据帧**：WebSocket通信的数据被分成**帧（Frame）** ，每个帧包含一个帧头和负载数据。帧头包含控制信息，如帧的类型、长度等。
4. **连接保持**：WebSocket连接是持久的，除非显式关闭或发生网络错误，否则连接会一直保持。

‍

‍

#### 握手示例

**客户端请求**

```
GET /chat HTTP/1.1
Host: server.example.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==
Sec-WebSocket-Version: 13
```

Connection: Upgrade, 请求提升长连接

传递Key信息

‍

**服务器响应**

```
HTTP/1.1 101 Switching Protocols
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo=
```

‍

‍

# 布隆过滤器

示例

‍

```java

public class BloomFilter {
    private final BitSet bitSet;
    private final int size;
    private final int hashCount;

    public BloomFilter(int size, int hashCount) {
        this.size = size;
        this.hashCount = hashCount;
        this.bitSet = new BitSet(size);
    }

    // 添加元素到布隆过滤器
    public void add(String value) {
        for (int i = 0; i < hashCount; i++) {
            int hash = hash(value, i);
            bitSet.set(Math.abs(hash % size), true);
        }
    }

    // 查询元素是否可能存在
    public boolean mightContain(String value) {
        for (int i = 0; i < hashCount; i++) {
            int hash = hash(value, i);
            if (!bitSet.get(Math.abs(hash % size))) {
                return false;
            }
        }
        return true;
    }

    // 简单的哈希函数
    private int hash(String value, int seed) {
        CRC32 crc32 = new CRC32();
        crc32.update((value + seed).getBytes(StandardCharsets.UTF_8));
        return (int) crc32.getValue();
    }

    public static void main(String[] args) {
        int size = 1000000;
        int hashCount = 3;
        BloomFilter bloomFilter = new BloomFilter(size, hashCount);

        // 示例数据
        String[] data = {"apple", "banana", "cherry", "date", "elderberry"};

        // 添加数据到布隆过滤器
        for (String item : data) {
            bloomFilter.add(item);
        }

        // 查询数据
        String query = "banana";
        if (bloomFilter.mightContain(query)) {
            System.out.println(query + " 可能存在");
        } else {
            System.out.println(query + " 不存在");
        }
    }
}
```

‍

## 什么是布隆过滤器？

布隆过滤器主要是用于检索一个元素是否在一个集合中。

布隆过滤器的核心思想是使用多个哈希函数来将元素映射到**位数组**中的多个位置上。当一个元素被加入到布隆过滤器中时，它会被多次哈希，并`将对应的位数组位置设置为1`​。当需要判断一个元素是否在布隆过滤器中时，我们只需将该元素进行多次哈希，并检查对应的位数组位置是否都为1，如果`其中有任意一位为0，则说明该元素不在集合中`​；如果所有位都为1，则说明该元素`可能`​在集合中（因为有可能存在哈希冲突），需要进一步检查。

‍

## 特性

1. **空间效率高**：布隆过滤器使用位数组和多个哈希函数来表示集合，所需的存储空间比传统的数据结构（如哈希表）要少得多。
2. **插入操作高效**：插入元素时，只需计算多个哈希值并设置相应的位数组位置，时间复杂度为 O(k)，其中 k 是哈希函数的数量。
3. **查询操作高效**：查询元素时，只需计算多个哈希值并检查相应的位数组位置，时间复杂度为 O(k)。
4. **不存在假阴性**：如果布隆过滤器判断一个元素不存在，那么该元素确实不存在。
5. **可能存在假阳性**：布隆过滤器可能会误判一个不存在的元素为存在，这种误判的概率可以通过调整位数组大小和哈希函数数量来控制。
6. **不可删除元素**：标准布隆过滤器不支持删除操作，因为删除元素可能会影响其他元素的存在判断。

‍

‍

‍

## 解决缓存穿透

使用BitMap作为布隆过滤器，将目前所有可以访问到的资源通过简单的映射关系放入到布隆过滤器中（哈希计算），当一个请求来临的时候先进行布隆过滤器的判断，如果有那么才进行放行，否则就直接拦截

‍

使用BitMap作为布隆过滤器，使用多个hash函数对key进行hash运算，得到一个整数索引值，对位数组长度进行取模运算得到一个位置，每个hash函数都会得到一个不同的位置，将这几个位置的值置为1。

向布隆过滤器查询某个key是否存在时，先把这个 key 通过相同的多个 hash 函数进行运算，查看对应的位置是否都为 1，

只要有一个位为零，那么说明布隆过滤器中这个 key 不存在；

如果这几个位置全都是 1，那么说明极有可能存在但不是一定存在；

因为这些位置的 1 可能是因为其他的 key 存在导致的，也就是前面说过的hash冲突

‍

‍

### 设置布隆过滤器的误判率

设置布隆过滤器的误判率为1%

布隆过滤器工厂接收预期数据量n和误差率p，根据上面两个数据计算出布隆过滤器的大小m(size)和哈希函数个数k。

当布隆过滤器实际的数据存储量超过预期数据量之后，误判率也会随之上涨。但是布隆过滤器是不能删除已有元素的，在这里我们采取的方案是再创建一个布隆过滤器

‍

‍

### 怎么用的设计模式？

使用工厂模式和策略模式实现布隆过滤器的大概流程如下：

1. **定义布隆过滤器接口**：首先定义一个布隆过滤器接口，包括添加元素和判断元素是否存在两个基本操作。
2. **实现具体的布隆过滤器类**：创建一个具体的布隆过滤器类，实现布隆过滤器接口中的方法。在这个类中，需要定义布隆过滗器的数据结构（比如位数组）、大小等属性。
3. **定义哈希策略接口**：定义一个哈希策略接口，包含计算哈希值的方法。
4. **实现具体的哈希策略类**：创建多个具体的哈希策略类，实现哈希策略接口中的方法，每个类对应一种哈希函数的计算方法。
5. **创建布隆过滤器工厂类**：定义一个布隆过滤器工厂类，其中包含一个用于创建布隆过滤器对象的工厂方法。工厂方法接受布隆过滤器的大小和哈希策略对象作为参数，并返回一个具体的布隆过滤器对象。
6. **使用布隆过滤器工厂**：在需要创建布隆过滤器对象的地方，调用布隆过滤器工厂的工厂方法来创建布隆过滤器对象，并传入相应的哈希策略对象。

‍

‍

‍

# 日志持久化-log4j等

没咋考

‍

‍

# Quartz 任务调度框架

没咋考

‍

快速开始

```java
public class StdSchedulerTest {
    public static void main(String[] args) {
        try {
            //1. StdSchedulerFactory工厂机制加载一个Scheduler
            Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();

            // 2. JobBuilder 定义一个JobDetail , 工作信息
            JobDetail job = JobBuilder.newJob(HelloJob.class)
                    .withIdentity("job1", "group1")
                    .build();

            // 3. TriggerBuilder定义一个trigger , 触发器 , 告诉你这个Job何时触发
            Trigger trigger = TriggerBuilder.newTrigger()
                    .withIdentity("trigger1", "group1")
                    .startNow()
                    .withSchedule(SimpleScheduleBuilder.simpleSchedule()
                            .withIntervalInMilliseconds(1000)
                            .repeatForever())
                    .build();
        
            // 4.告诉Scheduler , 我这个工作需要这个trigger
            scheduler.scheduleJob(job, trigger);

            //5. 启动
            scheduler.start();

            // 这里我们先阻塞着.. 
            System.in.read();
            // 6. 关闭
            scheduler.shutdown();

        } catch (SchedulerException | IOException se) {
            se.printStackTrace();
        }
    }
}
```

‍

其中 `com.example.springquartz.HelloJob`​ 需要实现`org.quartz.Job`​ 此接口

```java
public class HelloJob implements Job {
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {
        JobKey key = jobExecutionContext.getJobDetail().getKey();
        System.out.printf("group  %s , name : %s ,\t", key.getGroup(), key.getName());
        System.out.printf("Thread : %s - %s\n", Thread.currentThread().getName(), "Hello Job !");
    }
}
```

启动 : 日志信息 : 会告诉你任务何时调用的.

‍

‍

## SpringBoot整合Quartz

‍

基于Api的方式

```java
@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)
public class SpringQuartzApplication implements CommandLineRunner{

    public static void main(String[] args) {
        SpringApplication.run(SpringQuartzApplication.class, args);
    }


    @Override
    public void run(String... args) throws Exception {
        Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();
        JobDetail job = JobBuilder.newJob(MyJob.class).build();
        Trigger trigger = TriggerBuilder.newTrigger().startNow().withSchedule(SimpleScheduleBuilder.repeatHourlyForever().withIntervalInMilliseconds(1000)).build();
        scheduler.scheduleJob(job, trigger);
        scheduler.start();
    }
}
```

其实可以实现接口 `EnvironmentAware`​ 接口, 拿到Environment对象, 然后注入进去.

```java
StdSchedulerFactory factory = new StdSchedulerFactory(new Properties());
Scheduler scheduler = factory.getScheduler();
```

‍

‍

## SpringBoot处理

​`org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration`​ 这个类实现了自动注入的功能 .

他会有一个 `org.springframework.scheduling.quartz.SchedulerFactoryBean`​ 实例化, 同时 , 在返回之前, 会设置一个拦截器类似于 `org.springframework.boot.autoconfigure.quartz.SchedulerFactoryBeanCustomizer`​ , 可以设置一些`SchedulerFactoryBean`​ 的一些信息 . ....

首先就是 application.properties ,前缀是 spring.quartz.properties , 后缀还是原来的写法 ,

```properties
spring.quartz.properties.org.quartz.scheduler.instanceName=MyScheduler
spring.quartz.properties.org.quartz.threadPool.threadCount=4
spring.quartz.properties.org.quartz.jobStore.class=org.quartz.simpl.RAMJobStore
spring.quartz.job-store-type=memory
```

‍

### 用SchedulerFactoryBeanCustomizer实现注入

```java
@Bean
public SchedulerFactoryBeanCustomizer schedulerFactoryBeanCustomizer() {
    return new SchedulerFactoryBeanCustomizer() {
        @Override
        public void customize(SchedulerFactoryBean schedulerFactoryBean) {

            Properties properties = new Properties();
            try {
                properties.load(Thread.currentThread().getContextClassLoader().getResourceAsStream("quartz.properties"));
            } catch (IOException e) {
                e.printStackTrace();
            }
            schedulerFactoryBean.setQuartzProperties(properties);

            JobDetail job = JobBuilder.newJob(MyQuartzJobBean.class).storeDurably().build();
            Trigger trigger = TriggerBuilder.newTrigger().forJob(job).startNow()
                    .withSchedule(SimpleScheduleBuilder.repeatHourlyForever().withIntervalInMilliseconds(1000))
                    .build();
            // 
            schedulerFactoryBean.setJobDetails(job);
            // 
            schedulerFactoryBean.setTriggers(trigger);
        }
    };
}
```

‍

‍

### 直接注入

```java
@Bean
public Trigger schedulerFactoryBean() {
    return TriggerBuilder.newTrigger().forJob(jobDetail()).startNow()
            .withSchedule(SimpleScheduleBuilder.repeatHourlyForever().withIntervalInMilliseconds(1000))
            .build();
}

@Bean
public JobDetail jobDetail() {
    return JobBuilder.newJob(MyQuartzJobBean.class).storeDurably().build();
}
```

这里需要注意的是 需要将 `JobDetail`​ 设置storeDurably()为true , 不然启动会报错

```java
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'quartzScheduler' defined in class path resource [org/springframework/boot/autoconfigure/quartz/QuartzAutoConfiguration.class]: Invocation of init method failed; nested exception is org.quartz.SchedulerException: Jobs added with no trigger must be durable.
```

‍

## QuartzJobBean

​`org.springframework.scheduling.quartz.QuartzJobBean`​ 注入Bean, 这个很有特点, 所以特别拿出来,

他实现了 `org.quartz.Job`​ 接口, 实现了特定的方法

```java
public abstract class QuartzJobBean implements Job {

	@Override
	public final void execute(JobExecutionContext context) throws JobExecutionException {
		try {
            // 这里比较核心  ... 不好理解, 但是注释可以 , This implementation applies the passed-in job data map as bean property values, and delegates to executeInternal afterwards.
			BeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this);
			MutablePropertyValues pvs = new MutablePropertyValues();
			pvs.addPropertyValues(context.getScheduler().getContext());
			pvs.addPropertyValues(context.getMergedJobDataMap());
			bw.setPropertyValues(pvs, true);
		}
		catch (SchedulerException ex) {
			throw new JobExecutionException(ex);
		}
		executeInternal(context);
	}

	protected abstract void executeInternal(JobExecutionContext context) throws JobExecutionException;

}
```

​`assed-in job data map as bean property values`​ -> 将map中的内容设置为Bean的字段属性

```java
@PersistJobDataAfterExecution
@Component
public class MyQuartzJobBean extends QuartzJobBean {

    public static final String USER_NAME = "name";

    private String name;

    public void setName(String name) {
        this.name = name;
    }

    @Override
    protected void executeInternal(JobExecutionContext context) throws JobExecutionException {
        System.out.println("Name = " + name);
        JobDataMap map = context.getJobDetail().getJobDataMap();
        map.put(USER_NAME, UUID.randomUUID().toString());
    }
}
```

‍

‍

‍

# EasyExcel

​`EasyExcel`​ 是阿里巴巴开源的一个高效、简洁的Excel处理工具库，主要用于读取和写入Excel文件。它的设计目标是简化Excel文件的操作，提供更高的性能和更低的内存消耗。

‍

## 特点

1. **高性能**：相比于传统的POI，EasyExcel在处理大文件时具有更高的性能和更低的内存消耗。
2. **简洁易用**：提供了简洁的API，易于上手。
3. **支持多种格式**：支持Excel 2003（.xls）和Excel 2007及以上版本（.xlsx）。

‍

‍

### 解析Excel的操作步骤

‍

1. **引入依赖**  
    在`pom.xml`​中添加EasyExcel的依赖。

    ```xml
    <dependency>
        <groupId>com.alibaba</groupId>
        <artifactId>easyexcel</artifactId>
        <version>2.2.10</version>
    </dependency>
    ```
2. **定义数据模型**  
    创建一个Java类来映射Excel中的数据, 标记@ExcelProperty

    ```java
    public class UserData {
        @ExcelProperty("用户名")
        private String username;

        @ExcelProperty("年龄")
        private Integer age;

        // Getters and Setters
    }
    ```
3. **编写解析代码**  
    使用EasyExcel的API来读取Excel文件。

    ```java
    public class ExcelReader {
        public static void main(String[] args) {
            String fileName = "path/to/your/excel/file.xlsx";

            List<UserData> userList = EasyExcel.read(fileName)
                                               .head(UserData.class)
                                               .sheet()
                                               .doReadSync();

            for (UserData user : userList) {
                System.out.println(user.getUsername() + " - " + user.getAge());
            }
        }
    }
    ```

‍

### 解析过程

1. **读取文件**：通过`EasyExcel.read`​方法指定Excel文件路径。
2. **映射数据模型**：通过`head`​方法指定数据模型类。
3. **选择Sheet**：通过`sheet`​方法选择要读取的Sheet，默认读取第一个Sheet。
4. **同步读取**：通过`doReadSync`​方法同步读取数据，返回一个包含数据模型对象的列表。

‍

‍

# Netty

加分项

‍

> 其实就是深入理解和使用罢了。 想学习的 极客时间有一个课程不错， 基本覆盖的挺全的， 但是切记， 一定要多敲。 多看别人的代码， 而不是他写的Demo， 可以看看比如Dubbo框架 ， 或者 reactor-netty框架的源码， 好好看看。

‍

Netty 是一个基于 Java 的异步事件驱动的网络应用框架，用于快速开发高性能、高可靠性的网络服务器和客户端。它广泛应用于各种网络协议的实现，如 HTTP、WebSocket、TCP、UDP 等。

‍

‍

## 特点

* 高性能：Netty 采用了异步非阻塞的 I/O 模型，能够处理大量并发连接，性能优越。
* 易用性：提供了简洁的 API 和丰富的功能，易于上手。
* 可扩展性：支持多种协议和传输方式，具有很强的扩展性。
* 稳定性：经过大量项目的验证，具有很高的稳定性和可靠性。

‍

‍

## 核心组件

* Channel：表示一个网络连接，可以进行读写操作。
* EventLoop：处理 I/O 操作的事件循环。
* ChannelFuture：表示异步 I/O 操作的结果。
* ChannelHandler：处理 I/O 事件的处理器。
* Pipeline：维护一组 ChannelHandler 的链，负责处理 I/O 事件的流转。

‍

‍

# 序列化

‍

## 序列化原理

‍

‍

### Java反序列化的原理是什么? 为什么会有反序列化漏洞? 有哪些好用的反序列化工具吗？

Java反序列化的原理是将**字节流转换回Java对象**

反序列化的过程是通过读取字节流并重建对象的状态来实现的

‍

基本步骤：

1. **读取字节流**：从输入流中读取字节数据。
2. **创建对象**：根据字节数据创建对象实例。
3. **恢复状态**：将对象的状态恢复到序列化时的状态。

‍

反序列化漏洞通常发生在不安全的反序列化过程中，攻击者可以通过构造恶意的字节流来执行任意代码或破坏系统。主要原因包括：

1. **不可信数据源**：从不可信的数据源反序列化数据，可能会导致恶意数据被执行。
2. **类加载机制**：Java的类加载机制允许在反序列化过程中加载任意类，这可能被攻击者利用。
3. **缺乏验证**：反序列化过程中缺乏对数据的验证和过滤，导致恶意数据被执行。

‍

为了防止反序列化漏洞，可以采取以下措施：

1. **避免反序列化不可信数据**：尽量避免从不可信的数据源反序列化数据。
2. **使用白名单**：使用白名单机制，只允许反序列化特定的类。
3. **使用安全的反序列化库**：使用安全的反序列化库，如Gson、Jackson等。

‍

以下是一些常用的反序列化工具：

1. **Java自带的反序列化工具**：使用`ObjectInputStream`​进行反序列化。
2. **Gson**：用于JSON格式的反序列化。
3. **Jackson**：用于JSON格式的反序列化。

‍

‍

### java序列化和反序列化的底层是怎么实现的？

‍

Java序列化是通过`ObjectOutputStream`​将对象转换为二进制数据流保存起来，反序列化则由`ObjectInputStream`​将二进制数据重构成对象。

‍

主要步骤包括：

* **检查标记接口**：对象必须实现`java.io.Serializable`​标记接口，否则在序列化过程中会抛出`NotSerializableException`​
* **元数据写入**：序列化时，系统会写入类描述信息（包括类名、字段名、字段类型和版本号等），以便后续反序列化时判断版本兼容性。
* **实际数据写入**：利用反射机制遍历对象的字段，将其值写入到流中，同时维护对象引用的句柄，防止重复序列化同一对象（处理循环引用和共享引用）。
* **反序列化时**：`ObjectInputStream`​读取流中的元数据和字段数据，通过反射创建对象实例，并将读取到的值赋给对应字段。

‍

‍

### 介绍下 jableio.serializable, objectinputsstream, serialversionuid 这几个关键类/接口

‍

**java.io.Serializable**

这是一个标记接口，不包含任何方法。只要类实现了这个接口，JVM就会认为该类的对象是可序列化的。实现该接口后，对象就可以使用内置机制通过`ObjectOutputStream`​序列化，也可以通过`ObjectInputStream`​反序列化

‍

‍

**ObjectInputStream / ObjectOutputStream**

这两个类分别负责对象的反序列化和序列化

* ​`ObjectOutputStream`​：读取对象的内部状态，通过反射获取各个字段，然后将对象信息（包括类描述、字段信息、实际数据和对象句柄）写入到输出流
* ​`ObjectInputStream`​：从输入流中读取对象的元数据及字段值，然后利用反射构造出对象实例，并赋值给各字段

‍

‍

**serialVersionUID**

每个实现了Serializable接口的类，都可以定义一个静态常量`serialVersionUID`​来作为版本标识

* 在序列化时，这个值会被写入到序列化流中；反序列化时，JVM会比较流中的UID与当前类的UID是否一致
* 如果一致，则认为版本兼容，允许反序列化；如果不一致，则会抛出`InvalidClassException`​
* 如果没有显式定义，JVM会根据类的结构自动生成一个UID，但这容易受到代码改动的影响，所以建议手动定义以确保版本控制的一致性

‍

‍

### 假如我序列化后修改了内容，反序列化还能成功吗？

‍

**版本兼容性控制**  
序列化的版本控制依赖于`serialVersionUID`​。如果在序列化后对类进行了修改

* **兼容修改**：例如增加了新的字段（如果不影响已有字段的类型和语义）且显式声明了`serialVersionUID`​**保持不变**，此时反序列化时，新字段会获得默认值（如null、0等），而已有字段则能正确恢复。
* **非兼容修改**：例如更改了**已有**字段的类型或**删除**了关键字段，如果`serialVersionUID`​保持不变，反序列化可能会出现异常（如`InvalidClassException`​）或者数据不正确。
* **控制策略**：因此，推荐在类定义中显式指定`serialVersionUID`​，在修改类时，仔细评估修改是否与之前的版本兼容。如果需要兼容，则保持UID不变；如果不兼容，则**更新UID**以避免反序列化错误。

‍

‍

### transient关键字了解吗？

 (被这个关键字修饰的成员变量不会被序列化)

‍

**作用**  
被`transient`​修饰的字段在对象序列化过程中不会被写入到序列化流中，因此在反序列化时，这些字段会被初始化为默认值（例如对象为null，基本数据类型为0或false）。

‍

**使用场景**  
常用于不需要持久化的数据（如缓存、临时状态等），或者含有敏感信息的字段不希望被存储。

‍

‍

## 序列化协议

‍

### 数据序列化协议介绍

为什么要说 数据序列化协议？因为系统要么就是各个后端微服务之间通过 RPC 做交互，要么就是通过 HTTP/TCP 协议和前端(终端)做交互，因此不可避免的需要我们进行网络数据传输。而数据，只有序列化后，才方便进行网络传输。

序列化就是将数据结构或对象转换成二进制串的过程，也就是编码的过程，序列化后，会把数据转换为二进制串，然后可以进行网络传输；反序列化就是在序列化过程中所生成的二进制串转换成数据结构或者对象的过程，将二进制转换为对象后业务才好进行后续的逻辑处理。

常见的序列化协议如下

* Protocol Buffer（PB）
* JSON
* XML
* 内置类型（如 java 语言就有 java.io.Serializable）

常见的序列化协议的对比在网上有各种性能的对比，这里就不在贴相关截图了，只说结论：从性能上和使用广泛度上来看，后端服务之间现在一般推荐使用 PB。如果和前端交互，由于 HTTP 协议只能支持 JSON，因此一般只能 JSON。

‍

‍

‍

# 池化

‍

## 介绍

‍

### 池化技术（资源复用）

池化技术是非常常见的一个提高性能的技术，池化的核心思想就是对资源进行复用，减少重复创建销毁所带来的开销。复用就是创建一个池子，然后再在这个池子里面对各种资源进行统一分配和调度，不是创建后就释放，而是统一放到池子里面来复用，这样可以减少重复创建和销毁，从而提高性能。而这个资源就包括我们编程中常见到如 线程资源、网络连接资源、内存资源，具体到对应的池化技术层面就是 线程池（协程池）、连接池、内存池等。

‍

* 线程池（协程池）
* 连接池
* 内存池。常规的情况下，我们都是直接调用 new、malloc 等 Linux 操作系统的 API 来申请分配内存，而每次申请的内存块的大小不定，所以，当我们频繁 分配内存、回收内存的时候，会造成大量的内存碎片，同时每次使用内存都要重新分配也会降低性能。内存池就是先预先分配足够大的一块内存，当做我们的内存池，然后每次用户请求分配内存的时候，就会返回内存池中的一块空闲的内存，并将这块内存的标志置为已使用，当内存使用完毕释放内存的时候，也不是真正地调用 free 或 delete 来释放内存，而是把这块内存直接放回内存池内并且同时把标志置为空闲。一般业内都有相关的套件来帮我们来做这个事情，比如在 C/C++ 语言里面，都有相关库去封装原生的 malloc，glibc 实现了一个 ptmalloc 库，Google 实现了一个 tcmalloc 库
* 对象池。前面几种类型的池化技术，其实都可以作为对象池的各种应用，因为各种资源都可以当做一个对象。对象池就是避免大量创建同一个类型的对象，从而进行池化，保证对象的可复用性。
