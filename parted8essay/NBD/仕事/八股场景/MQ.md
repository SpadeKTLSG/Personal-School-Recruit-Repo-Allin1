‍

‍

# 概念

‍

## 零碎

‍

‍

### 消队使用场景

‍

‍

#### 商品秒杀

MQ 可以用来实现**削峰填谷**，解决短时间内爆发式的请求任务

在不使用 MQ 的情况下会导致服务处理不过来，出现应用程序假死的情况，而使用了 MQ 之后可以把这些请求先暂存到消息队列中，然后进行排队执行，那么就不会出现应用程序假死的情况了

> 做秒杀活动时，会发生短时间内出现爆发式的用户请求，如果不采取相关的措施，会导致服务器忙不过来，响应超时的问题，轻则会导致服务假死，重则会让服务器直接宕机，给用户带来的体验也非常不好。如果这个时候加上了消息队列，服务器接收到用户的所有请求后，先把这些请求全部写入到消息队列中再排队处理，这样就不会导致同时处理多个请求的情况；如果消息队列长度超过可以承载的最大数量，那么我们可以抛弃当前用户的请求，通知前台用户“页面出错啦，请重新刷新”等提示，这样就会有更好的交互体验。

‍

‍

#### 系统解耦

把系统的业务功能**模块化**，实现系统的解耦。

> 每个功能的实现独立开，只需要一个订阅或者取消订阅的开关就可以了，当需要增加功能时，只需要打开订阅“用户信息完善”的队列就行，如果过两天不用了，再把订阅的开关关掉就行了，这样我们就不用来来回回的改业务代码了，也就轻松的实现了系统模块间的解耦。

‍

‍

#### 日志记录

> 我们大部分的日志记录行为其实是和前台用户操作的主业务没有直接关系的，只是我们的运营人和经营人员需要拿到这部分用户操作的日志信息，来进行用户行为分析或行为监控。在我们没有使用消息队列之前，笼统的做法是当有用户请求时，先处理用户的请求再记录日志，这两个操作是放在一起的，而前台用户也需要等待日志添加完成之后才能拿到后台的响应信息，这样其实浪费了前台用户的部分时间。此时我们可以使用消息队列，当响应完用户请求之后，只需要把这个操作信息放入消息队列之后，就可以直接返回结果给前台用户了，无序等待日志处理和日志添加完成，从而缩短了前台用户的等待时间。

‍

‍

‍

### MQ 特点及注意事项

* **先进先出**：消息队列的顺序一般在入列时就基本确定了，最先到达消息队列的信息，一般情况下也会先转发给订阅的消费者，我们把这种实现了先进先出的数据结构称之为队列。
* **发布、订阅工作模式**：生产者也就是消息的创建者，负责创建和推送数据到消息服务器；消费者也就是消息的接收方，用于处理数据和确认消息的消费；消息队列也是 MQ 服务器中最重要的组成元素之一，它负责消息的存储，这三者是 MQ 中的三个重要角色。而它们之间的消息传递与转发都是通过发布以及订阅的工作模式来进行的，即生产者把消息推送到消息队列，消费者订阅到相关的消息后进行消费，在消息非阻塞的情况下，此模式基本可以实现同步操作的效果。

  此种工作模式会把请求的压力转移给 MQ 服务器，以减少了应用服务器本身的并发压力。
* **持久化**：持久化是把消息从内存存储到磁盘的过程，并且在服务器重启或者发生宕机的情况下，重新启动服务器之后是保证数据不会丢失的一种手段，也是目前主流 MQ 中间件都会提供的重要功能。
* **分布式**：MQ 的一个主要特性就是要应对大流量、大数据的高并发环境，一个单体的 MQ 服务器是很难应对这种高并发的压力的，所以 MQ 服务器都会支持分布式应用的部署，以分摊和降低高并发对 MQ 系统的冲击。
* **消息确认**：消息消费确认是程序稳定性和安全性的一个重要考核指标，假如消费者在拿到消息之后突然宕机了，那么 MQ 服务器会误认为此消息已经被消费者消费了，从而造成消息丢失的问题，而目前市面上的主流 MQ 都实现了消息确认的功能，保证了消息不会丢失，从而保证了系统的稳定性。

‍

‍

‍

‍

### MQ对比

Redis、RabbitMQ、Kafka、ActiveMQ 和 RocketMQ

|特性|ActiveMQ|RabbitMQ|RocketMQ|Kafka|
| ------------| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| -----------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|单机吞吐量|万级，吞吐量比RocketMQ和Kafka要低一个数量级|万级，吞吐量比RocketMQ和Kafka要低一个数量级|10万级，RocketMQ也是可以支撑高吞吐的一种MQ|10万级1这是kafka最大的优点，就是吞吐量高。一般配置和数据类的系统进行实时数据计算、日志采集等场景|
|时效性|ms级|微妙级，这是RabbitMQ的一大特点，就是延迟最低|ms级|延迟在ms级内|
|可用性|基于主从架构实现高可用|高，基于主从架构实现高可用|非常高，分布式架构|非常高，kafka是分布式的，一个数据多个副本，少数机器宕机后，不会丢失数据，不会导致不可用|
|消息可靠性|有较低的概率丢失数据|消息不丢失|经过参数优化配置，可以做到0丢失|经过参数优化配置可以做到0丢失|
|核心特点|MQ领域的功能及其完备|基于Erlang开发，所以并发能力强，性能及其好，延时很低|MQ功能较为完善，还是分布式的，扩展性好|功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是实时上的标准。|
||非常成熟，功能强大，在业内大量公司以及项目都有应用。 但是偶尔消息丢失的概率，并且现在社区以及国内应用都越来越少，官方社区对ActiveMQ5.X维护越来越少，而且确实主要是基于解耦和异步来用的，较少在大规模吞吐场景中使用|erlang语言开发的，性能及其好，延时很低。而且开源的版本，就提供的管理界面非常棒，在国内一些互联网公司近几年用RabbitMQ也是比较多一些，特别适用于中小型的公司 缺点显而易见，就是吞吐量会低一些，这是因为它做的实现机制比较中，因为使用erlang开发，目前没有多少公司使用其开发。所以针对源码界别的定制，非常困难，因此公司的掌控非常弱，只能依赖于开源社区的维护。|接口简单易用，毕竟在阿里大规模应用过，有阿里平台保障，日处理消息上 百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是OK的，还可以支撑大规模的topic数量，支持复杂MQ业务场景。|仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级别的延迟，极高的可用性以及可靠性，分布式可以任意扩展。 同时kafka最好是支撑较少的topic数量即可，保证其超高的吞吐量。|

‍

‍

#### Redis MQ

轻量级的消息中间件

Redis 是一个高效的内存性数据库中间件，使用 Redis 也可以实现消息队列的功能。

早期的 Redis（Redis 5.0 之前）是不支持消息确认的，那时候我们可以通过 List 数据类型的 lpush 和 rpop 方法来实现队列消息的存入和读取功能，或者使用 Redis 提供的发布订阅（pub/sub）功能来实现消息队列，但这种模式不支持持久化，List 虽然支持持久化但不能设置复杂的路由规则来匹配多个消息，并且他们二者都不支持消息消费确认。

于是在 Redis 5.0 之后提供了新的数据类型 Stream 解决了消息确认的问题，但它同样不能提供复杂的路由匹配规则，因此在业务不复杂的场景下可以尝试性的使用 Redis 提供的消息队列。

‍

‍

#### Kafka

Kafka 是 LinkedIn 公司开发的基于 **ZooKeeper** 的多分区、多副本的分布式消息系统，它于 2010 年贡献给了 Apache 基金会，并且成为了 Apache 的顶级开源项目。其中 ZooKeeper 的作用是用来为 Kafka 提供**集群元数据管理以及节点的选举和发现**等功能。

与 RabbitMQ 比较类似，一个典型的 Kafka 是由多个 Broker、多个生产者和消费者，以及 ZooKeeper 集群组成的，其中 Broker 可以理解为一个代理，Kafka 集群中的一台服务器称之为一个 Broker

‍

##### Kafka VS RabbitMQ

Kafka（2.0.0）和 RabbitMQ（3.6.10）的区别主要体现在以下几点：

* Kafka 支持**消息回溯**，它可以根据 Offset（消息偏移量）、TimeStamp（时间戳）等维度进行消息回溯，而 RabbitMQ 并不支持消息回溯；
* Kafka 的消息消费是基于**拉取数据**的模式，也就是消费者主动向服务器端发送拉取消息请求，而 RabbitMQ 支持拉取数据模式和主动推送数据的模式，也就说 RabbitMQ 服务器会主动把**消息推送给订阅的消费者**；
* 在相同配置下，Kafka 的**吞吐量**通常会比 RabbitMQ 高一到两个级别，比如在单机模式下，RabbitMQ 的吞吐量大概是万级别的处理能力，而 Kafka 则可以到达十万甚至是百万的吞吐级别；
* Kafka 从 0.11 版本就开始支持**幂等性**了，当然所谓的幂等性指的是对单个生产者在单分区上的单会话的幂等操作，但对于**全局幂等性**则还需要结合业务来处理

  比如，消费者在消费完一条消息之后没有来得及确认就发生异常了，等到恢复之后又得重新消费原来消费过的消息，类似这种情况，是无法在消息中间件层面来保证的，这个时候则需要引入更多的外部资源来保证全局幂等性，比如唯一的订单号、消费之前先做去重判断等；而 RabbitMQ 是没有幂等性功能支持的；
* RabbitMQ 支持多租户的功能，也就是常说的 Virtual Host（vhost），每一个 vhost 相当于一个独立的小型 RabbitMQ 服务器，它们拥有自己独立的交换器、消息队列及绑定关系等，并且拥有自己独立权限，而且多个 vhost 之间是绝对隔离的，但 Kafka 并不支持**多租户**的功能。

Kafka 和 RabbitMQ 都支持分布式集群部署，并且都支持数据持久化和消息消费确认等 MQ 的核心功能，对于 MQ 的选型要结合自己团队本身的情况，从性能、稳定性及二次开发的难易程度等维度来进行综合的考量并选择。

‍

‍

#### 综上

Rabbit说法

> kafka以**吞吐量高**而闻名，不过其数据**稳定性**一般，而且无法保证消息有序性。我们公司的日志收集也有使用，业务模块中则使用的RabbitMQ
>
> 阿里巴巴的 RocketMQ 基于Kafka的原理，弥补了Kafka的缺点，继承了其高吞吐的优势，其客户端目前以Java为主 (和阿里内部绑定)
>
> RabbitMQ基于面向并发的语言Erlang开发，吞吐量不如Kafka，但是对我们公司来讲够用了。而且消息可靠性较好，并且消息延迟极低，集群搭建比较方便。支持多种协议，并且有各种语言的客户端，比较灵活。Spring对RabbitMQ的支持也比较好，使用起来比较方便，比较符合我们公司的需求。
>
> 综合考虑我们公司的并发需求以及稳定性需求，我们选择了RabbitMQ

* 一般的业务要引入MQ，最早大家都是用ActiveMQ，但是现在大家用的不多了，没有经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了，不太使用
* RabbitMQ后面被大量的中小型公司所使用，但是**erlang语言**阻碍了大量的Java工程师深入研究和掌握它，对公司而言，几乎处于不可控的状态，但是RabbitMQ目前开源稳定，活跃度也表较高。
* RocketMQ是**阿里开源的一套消息中间件**，目前也已经经历了天猫双十一，同时底层使**用Java进行开发**

‍

如果中小型企业技术实力一般，技术挑战不是很高，可以推荐，RabbitMQ。如果公司的基础研发能力很强，想精确到**源码级别的掌握**，那么推荐使用RocketMQ。同时如果项目是聚焦于**大数据领域的实时计算，日志采集等场景，那么Kafka是业内标准**。

‍

‍

‍

## 为什么使用MQ？

其实就是问问你消息队列有哪些场景，然后你项目里面的具体是什么场景，说说你在这个场景里用什么消息队列是什么？

‍

消息队列的场景使用场景很多，主要是三个：解耦、异步、和削峰

还有些特种

延迟队列：基于RabbitMQ的死信队列或者DelayExchange插件，可以实现消息发送后，延迟接收的效果

‍

### 解耦

‍

**不使用MQ时**

A系统发送数据到B、C、D系统，但没有使用消息队列时候的耦合场景, 因为A系统和其它各种系统耦合起来，那么需要处理的事情很多

‍

‍

**使用MQ后**

系统A发送一条消息，到消息队列中，哪个系统需要获取到哪里，那么从MQ中消费数据，如果新系统E加入的话，那么只需要编写代码，然后也直接从MQ中消费即可，当系统D不需要这个数据时，那么只需要不对该消息进行消费即可。系统A不需要考虑给谁发送数据，也不需要维护这个代码，不需要考虑人家是否调用成功、失败、超时等等情况

‍

总结：通过一个MQ，发布和订阅模型，Pub/Sub模型，系统A就和其它系统彻底解耦。

需要考虑一下负责的系统中，是否有类似的场景，就是一个系统或者一个模块，调用了多个系统，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要同步调用接口的，如果用MQ给他异步化解耦，也是可以的

‍

‍

### 异步

‍

**不用MQ的同步高延时请求场景**

下面的一个场景就是系统A，调用了其它三个系统的服务，我们发现用户在执行一个请求后，需要花费很长的时间

我们发现，用户执行一个接口，就需要花费350毫秒，假设我们将每个接口的耗时增加，可能会将近花费1秒，这个时候一般用户几乎不能接受，因为一般互联网类的企业，对用户的直接操作，一般要求是每个请求都必须在200ms以内完成，因为这个是对用户是无感知的

先返回结果再说

‍

### 削峰

一般的MySQL，抗到QPS=2000的时候就已经达到了瓶颈，如果每秒请求达到了5000的话，可能直接就把MySQL打死了。如果MySQL被打死，然后整个系统就崩溃，然后系统就没法使用。

但是中午的高峰期过了之后，到下午的时候，就成了低峰期，可能也就一万用户同时在网站上操作，每秒的请求数量可能就50个请求，对整个系统几乎没有任何压力

‍

削峰就是大量的请求过来，然后MQ将其消化掉了，然后通过其它系统从MQ中取消息，在逐步进行消费，保证系统的有序运行。一般高峰期不会持续太长，在一段时间后，就会被下游系统消化掉。

‍

‍

## 消息队列缺点

* 系统可用性降低：引入 MQ 系统，则意味着新增了一套系统，并且其他的业务系统会对 MQ 系统进行深度依赖，系统部署的越多则意味着发生故障的可能性就越大，如果 MQ 系统挂掉的话可能会导致整个业务系统瘫痪。
* 系统复杂性提高：引入 MQ 系统后，需要考虑消息丢失、消息重复消费、消息的顺序消费等问题，同时还需要引入新的客户端来处理 MQ 的业务，增加了编程的运维门槛，增加了系统的复杂性。硬生生加个MQ进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？
* 一致性问题：A系统处理完了直接返回成功了，人都以为你的请求成功了，但是问题是，要在BCD三个系统中，BD两个系统写库成功了，结果C系统写库失败了，这样就会存在数据不一致的问题。

‍

不要过度依赖 MQ，比如发送短信验证码或邮件等功能，这种低频但有可能比较耗时的功能可以使用多线程异步处理即可，不用任何的功能都依赖 MQ 中间件来完成，但像秒杀抢购可能会导致超卖（也就是把货卖多了，库存变成负数了）等短时间内高并发的请求，此时建议使用 MQ 中间件。

‍

## 防止重复消费？/ MQ幂等性怎么保证

消息重复消费的原因多种多样，不可避免。所以只能从**消费者端**入手，只要能保证消息处理的**幂等性**就可以确保消息不被重复消费。

‍

幂等性的保证方案

* 给每一条消息都添加一个**唯一id**，在本地记录消息表及消息状态，处理消息时基于数据库表的id唯一性做判断
* 同样是记录消息表，利用消息状态字段实现基于**乐观锁**的判断，保证幂等
* 基于**业务本身**的幂等性。比如根据id的删除、查询业务天生幂等；新增、修改等业务可以考虑基于数据库id唯一性、或者乐观锁机制确保幂等。本质与消息表方案类似。

‍

MQ（消息队列）的幂等性可以通过多种措施来保证，确保系统即使在出现重复消息的情况下也能保持数据的一致性和正确性。具体如下：

1. **生成全局唯一的inner-msg-id**：在消息发送端（上半场），MQ客户端应为每条消息生成一个全局唯一且业务无关的inner-msg-id。这个ID由MQ保证其唯一性，并且对业务透明。这样，即使在网络波动或超时导致的重发情况下，MQ服务器可以利用这个ID进行去重，确保相同的消息不会被处理多次。
2. **业务层的去重处理**：在消息的消费端（下半场），业务系统需要根据业务特点带入业务相关的biz-id。消费端通过这个biz-id来进行去重，以保证对于同一业务操作，即使收到了多次相同消息，也只会被处理一次。这要求业务系统具备去重逻辑，通常涉及到数据库的唯一约束或者分布式锁等机制来保证操作的幂等性。
3. **利用乐观锁机制**：借鉴数据库中乐观锁的思想，可以为涉及状态变更的业务数据添加版本号。每次更新前先检查版本号，只有在版本号匹配的情况下才执行更新操作，并更新版本号。这种方式可以防止并发下的重复操作影响数据一致性。
4. **消息确认机制**：MQ客户端在发送消息给MQ服务器后，等待服务器的确认（ACK）。如果确认丢失或超时，客户端会重发消息。为了避免因此导致的重复消息处理，MQ服务器内部需要有机制识别并丢弃重复的消息，例如利用上述提到的inner-msg-id进行去重。
5. **消费端幂等设计**：在消费端实现业务逻辑时，需要考虑到消息可能会被重复投递的情况。因此，消费端的业务处理逻辑应当设计成幂等的，即多次执行相同的操作不会对最终结果产生影响。
6. **事务性消息**：对于需要保证精确一次消费的场景，可以使用事务性消息。这意味着消息的发送和消费是原子性的，要么都成功，要么都失败。这种方式下，系统能更好地控制幂等性，但可能会牺牲一些性能。
7. **限流和补偿机制**：在高并发场景下，适当的限流策略可以避免系统因过载而产生错误的重复操作。同时，建立补偿机制可以在检测到异常操作时进行修正。

综上所述，保证MQ幂等性是一个系统性工程，既涉及到技术层面的改进，如ID生成、去重、乐观锁等，也需要业务逻辑层面的支持，如业务去重、幂等设计等。

‍

‍

## **保证消息的可靠性？**

‍

### 生产者发送消息时可能因为网络问题导致消息没有到达交换机：

publisher confirm机制

* 生产者发送消息后，可以编写ConfirmCallback函数
* 消息成功到达交换机后，RabbitMQ会调用ConfirmCallback通知消息的发送者，返回ACK
* 消息如果未到达交换机，RabbitMQ也会调用ConfirmCallback通知消息的发送者，返回NACK
* 消息超时未发送成功也会抛出异常

‍

事务机制

* 允许生产者在发送消息时将一组操作作为一个原子操作来执行。如果任何操作失败，整个事务将被回滚，从而确保消息不会部分发送或丢失
* 事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错
* 事务机制会增加消息发送的延迟，因为每个事务都需要等待RabbitMQ的确认

‍

### 消息到达交换机后，如果未能到达队列，也会导致消息丢失：

publisher return 机制

* 生产者可以定义 ReturnCallback 函数
* 消息到达交换机，未到达队列，RabbitMQ会调用ReturnCallback通知发送者，告知失败原因
* 消息超时未发送成功也会抛出异常

‍

### 消息到达队列后，MQ宕机也可能导致丢失消息：

持久化功能，集群的主从备份功能

* 消息持久化，RabbitMQ会将交换机、队列、消息持久化到磁盘，宕机重启可以恢复消息
* 普通集群, 普通集群模式下，消息只保存在主节点，主节点宕机后，消息会丢失
* 镜像集群，仲裁队列，都可以提供主从备份功能，主节点宕机，从节点会自动切换为主，数据依然在

‍

‍

### 消息投递给消费者后，如果消费者处理不当，也可能导致消息丢失

SpringAMQP基于RabbitMQ提供了消费者确认机制、消费者重试机制，消费者失败处理策略：

* 消费者的确认机制：

  * 消费者处理消息成功，未出现异常时，Spring返回ACK给RabbitMQ，消息才被移除
  * 消费者处理消息失败，抛出异常，宕机，Spring返回NACK或者不返回结果，消息不被异常
* 消费者重试机制：

  * 默认情况下，消费者处理失败时，消息会再次回到MQ队列，然后投递给其它消费者。Spring提供的消费者重试机制，则是在处理失败后不返回NACK，而是直接在消费者本地重试。多次重试都失败后，则按照消费者失败处理策略来处理消息。避免了消息频繁入队带来的额外压力。
* 消费者失败策略：

  * 当消费者多次本地重试失败时，消息默认会丢弃。
  * Spring提供了Republish策略，在多次重试都失败，耗尽重试次数后，将消息重新投递给指定的异常交换机，并且会携带上异常栈信息，帮助定位问题。(死信队列)

‍

‍

## 保证消息的顺序性？

其实RabbitMQ是队列存储，天然具备先进先出的特点，只要消息的发送是有序的，那么理论上接收也是有序的。不过当一个队列绑定了**多个消费者**时，可能出现消息轮询投递给消费者的情况，而消费者的处理顺序就无法保证了。

‍

因此，要保证消息的有序性，需要做的下面几点：

* 保证消息发送的有序性
* 保证一组有序的消息都发送到同一个队列
* 拆分保证一个队列只包含一个消费者
* 一个队列只包含一个消费者, 但是他内部用内存队列(编码)做排队, 然后(调用)分发给底层不同的 worker 来处理

‍

‍

## 避免消息堆积？

消息发送的速度超过了消费者消息处理的速度。因此解决方案无外乎以下三点：

* 提高消费者处理速度
* 增加更多消费者
* 增加队列消息存储上限

‍

### 1）提高消费者处理速度

消费者处理速度是由业务代码决定的，所以我们能做的事情包括：

* 尽可能优化业务代码，提高业务性能
* 接收到消息后，开启线程池，并发处理多个消息
* 对不同消息进行分层级, 优先处理要紧内容或是能够快速死亡的玩意

优点：成本低，改改代码即可

缺点：开启线程池会带来额外的性能开销，对于高频、低时延的任务不合适。推荐任务执行周期较长的业务。

‍

‍

### 2）增加更多消费者

一个队列绑定多个消费者，共同争抢任务，自然可以提供消息处理的速度。

优点：简单粗暴

缺点：成本太高

‍

‍

### 3）增加队列消息存储上限

在RabbitMQ的1.8版本后，加入了新的队列模式：Lazy Queue

这种队列不会将消息保存在内存中，而是在收到消息后**直接写入磁盘**中，理论上没有存储上限。可以解决消息堆积问题。

优点：磁盘存储更安全；存储无上限；避免内存存储带来的Page Out问题，性能更稳定；

缺点：磁盘存储受到IO性能的限制，消息**时效性**不如内存模式，但影响不大。

‍

‍

‍

## MQ的通讯模式

1. **点对点通讯**：点对点方式是最为传统和常见的通讯方式，它支持一对一、一对多、多对多、多对一等多种配置方式，支持树状、网状等多种拓扑结构。
2. **多点广播**：MQ适用于不同类型的应用。其中重要的，也是正在发展中的是"多点广播"应用，即能够将消息发送到多个目标站点(Destination List)。可以使用一条MQ指令将单一消息发送到多个目标站点，并确保为每一站点可靠地提供信息。MQ不仅提供了多点广播的功能，而且还拥有智能消息分发功能，在将一条消息发送到同一系统上的多个用户时，MQ将消息的一个复制版本和该系统上接收者的名单发送到目标MQ系统。目标MQ系统在本地复制这些消息，并将它们发送到名单上的队列，从而尽可能减少网络的传输量。
3. **发布/订阅(Publish/Subscribe)模式**：发布/订阅功能使消息的分发可以突破目的队列地理指向的限制，使消息按照特定的主题甚至内容进行分发，用户或应用程序可以根据主题或内容接收到所需要的消息。发布/订阅功能使得发送者和接收者之间的耦合关系变得更为松散，发送者不必关心接收者的目的地址，而接收者也不必关心消息的发送地址，而只是根据消息的主题进行消息的收发。在MQ家族产品中，MQ Event Broker是专门用于使用发布/订阅技术进行数据通讯的产品，它支持基于队列和直接基于TCP/IP两种方式的发布和订阅。
4. **集群(Cluster)** ：为了简化点对点通讯模式中的系统配置，MQ提供 Cluster 的解决方案。集群类似于一个 域(Domain) ，集群内部的队列管理器之间通讯时，不需要两两之间建立消息通道，而是采用 Cluster 通道与其它成员通讯，从而大大简化了系统配置。此外，集群中的队列管理器之间能够自动进行负载均衡，当某一队列管理器出现故障时，其它队列管理器可以接管它的工作，从而大大提高系统的高可靠性

‍

‍

## 多线程异步和MQ的区别

* **CPU消耗**。多线程异步可能存在CPU竞争，而MQ不会消耗本机的CPU。
* MQ 方式实现异步是完全**解耦**的，适合于大型互联网项目。
* **削峰或者消息堆积能力**。当业务系统处于高并发，MQ可以将消息堆积在Broker实例中，而多线程会创建大量线程，甚至触发拒绝策略。
* 使用MQ引入了中间件，增加了项目复杂度和运维难度。

总的来说，规模比较小的项目可以使用多线程实现异步，大项目建议使用MQ实现异步。

‍

## MQ 中的消息过期失效了怎么办？

如果使用的是RabbitMQ的话，RabbtiMQ 是可以设置过期时间的（TTL）。如果消息在 Queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。这时的问题就不是数据会大量积压在 MQ 里，而是大量的数据会直接搞丢。这个情况下，就不是说要增加 Consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。

我们可以采取一个方案，就是批量重导。就是大量积压的时候，直接将数据写到数据库，然后等过了高峰期以后将这批数据一点一点的查出来，然后重新灌入 MQ 里面去，把丢的数据给补回来。

‍

‍

## 消息队列里面拉取模式和推送模式的比较

在消息队列系统中，推送模式（Push）和拉取模式（Pull）是两种基本的消息传输机制。它们之间存在一定的区别。具体分析如下：

* 推送模式：**在MQ中也就是Broker收到消息后主动推送给Consumer的操作，叫做推模式。** 推模式的实现是客户端会与服务端（Broker）建立长连接，当有消息时服务端会通过长连接通道将消息主动推送给客户端，这样客户端就能实时消费到最新的消息。优点： 实时性强，有消息立马推送给客户端，吞吐量大。客户端实现简单，只需要监听服务端的推送即可。

  缺点： 容易导致客户端发生消息堆积的情况，因为每个客户端的消费能力是不同的，如果简单粗暴的有消息就推送，就会会出现堆积情况。
* 拉取模式：在MQ中也就是**客户端主动从服务器Broker端获取信息**。很多拉模式都是基于长轮询来实现。长轮询就是客户端向服务端发起请求，如果此时有数据就直接返回，如果没有数据就保持连接，等到有数据时就直接返回。如果一直没有数据，超时后客户端再次发起请求，保持连接，这就是长轮询的实现原理。很多的开源框架都是用的这种方式，比如配置中心Apollo的推送优点： 不会造成客户端消息积压，消费完了再去拉取，主动权在自己手中。长轮询实现的拉模式实时性也能够保证。

  缺点： 实时性较差，针对于服务器端实时更新的信息，客户端难以获取实时信息；

推和拉都有各自的优势和劣势，不过目前主流的消息队列大部分都用的拉模式，比如RocketMQ，Kafka。

‍

‍

## 什么是RabbitMQ

RabbitMQ 是一个在 AMQP（Advanced Message Queuing Protocol ）基础上实现的整，体上是一个生产者与消费者模型，主要负责接收、存储和转发消息。

‍

### 什么是AMQP

RabbitMQ 就是 AMQP 协议的 `Erlang`​ 的实现(当然 RabbitMQ 还支持 `STOMP2`​、 `MQTT3`​ 等协议 ) AMQP 的模型架构 和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定 。

RabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 协议中相 应的概念。目前 RabbitMQ 最新版本默认支持的是 AMQP 0-9-1。

‍

**AMQP 协议的三层**：

* **Module Layer**:协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。
* **Session Layer**:中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。
* **TransportLayer**:最底层，主要传输二进制数据流，提供帧的处理、信道服用、错误检测和数据表示等。

‍

**AMQP 模型的三大组件**：

* **交换器 (Exchange)** ：消息代理服务器中用于把消息路由到队列的组件。
* **队列 (Queue)** ：用来存储消息的数据结构，位于硬盘或内存中。
* **绑定 (Binding)** ：一套规则，告知交换器消息应该将消息投递给哪个队列。

‍

‍

# 大块

‍

## 集群

RabbitMQ是比较有代表性的，因为是基于主从做高可用性的。

RabbitMQ 三种模式：单机模式，普通集群模式，镜像集群模式

‍

---

RabbitMQ 集群是由多个节点组成，但默认情况下每个节点并不是存储所有队列的完整拷贝，这是出于存储空间和性能的考虑，因为如果存储了队列的完整拷贝，那么就会有很多冗余的重复数据，并且在新增节点的情况下，不但没有新增存储空间，反而需要更大的空间来存储旧的数据；

同样的道理，如果每个节点都保存了所有队列的完整信息，那么非查询操作的性能就会很慢，就会需要更多的网络带宽和磁盘负载来存储这些数据。

‍

为了能兼顾性能和稳定性，RabbitMQ 集群的节点分为两种类型，即磁盘节点和内存节点，对于磁盘节点来说显然它的优势就是稳定，可以把相关数据保存下来，若 RabbitMQ 因为意外情况宕机，重启之后保证了数据不丢失；而内存节点的优势是快，因为是在内存中进行数据交换和操作，因此性能比磁盘节点要高出很多倍。

如果是单个 RabbitMQ 那么就必须要求是磁盘节点，否则当 RabbitMQ 服务器重启之后所有的数据都会丢失，这样显然是不能接受的。在 RabbitMQ 的集群中，至少需要一个磁盘节点，这样至少能保证集群数据的相对可靠性。

如果集群中的某一个磁盘节点崩溃了，此时整个 RabbitMQ 服务也不会处于崩溃的状态，不过部分操作会受影响，比如不能创建队列、交换器、也不能添加用户及修改用户权限，更不能添加和删除集群的节点等功能。

> 小贴士：对于 RabbitMQ 集群来说，我们启动集群节点的顺序应该是先启动磁盘节点再启动内存节点，而关闭的顺序正好和启动的顺序相反，不然可能会导致 RabbitMQ 集群启动失败或者是数据丢失等异常问题。

‍

‍

### 单机模式

就是demo级别的，一般就是本地启动后玩一玩，没有人生产环境中使用。

‍

### 普通集群模式

* 意思就是在多台机器上启动多个RabbitMQ实例，每台机器启动一个，但是创建的Queue，只会放在一个RabbitMQ实例上，但是每个实例都同步queue元数据，在消费的时候，实际上是连接到另外一个实例上，那么这个实例会从queue所在实例上拉取数据过来，这种方式确实很麻烦，也不怎么好，没做到所谓的分布式 ，就是个普通集群。因为这导致你要么消费每次随机连接一个实例，然后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。
* 而且如果那个放queue的实例宕机了，会导致接下来其它实例无法从那个实例拉取，如果 你开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，得等到这个实例恢复了，然后才可以继续从这个queue拉取数据。

‍

这里没有什么所谓的高可用性可言，这个方案主要就是为了解决吐吞量，就是集群中的多个节点来服务于某个queue的读写操作。

‍

存在两个缺点

* 可能会在RabbitMQ中存在大量的数据传输
* 可用性没有什么保障，如果queue所在的节点宕机，就会导致queue的消息丢失

‍

‍

### 集群镜像模式

这种模式，才是RabbitMQ的高可用模式，和普通的集群模式不一样的是，你创建的queue无论元数据还是queue里的消息都会存在与多个实例中，然后每次你写消息到queu的时候，都会自动把消息推送到多个实例的queue中进行消息同步。

这样的好处在于，你任何一个机器宕机了，别的机器都可以用。

坏处在于，性能开销提升，消息同步所有的机器，导致网络带宽压力和消耗增加，第二就是没有什么扩展性科研，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue

‍

那么如何开启集群镜像策略呢？就是在RabbitMQ的管理控制台，新增一个策略，这个策略就是镜像集群模式下的策略，指定的时候，可以要求数据同步到所有的节点，也可以要求就 同步到指定数量的节点，然后再次创建queue的时候，应用这个策略，就会自动将数据同步到其它节点上去了。

集群镜像模式下，任何一个节点宕机了都是没问题的，因为其他节点还包含了这个queue的完整的数据，别的consumer可以到其它活着的节点上消费数据。

但是这个模式还存在问题：就是不是分布式的，如果这个queue的数据量很大，大到这个机器上的容量无法容纳的时候，此时应该怎么办呢？

‍

‍

‍

# 高级

‍

‍
