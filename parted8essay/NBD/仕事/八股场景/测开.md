‍

‍

# 概念

‍

## 零碎

‍

### 你对SQA的职责和工作活动(如软件度量)的理解?

SQA就是独立于软件开发的项目组，通过对软件开发过程的监控，来保证软件的开发流程按照指定的CMM规程(如果有相应的CMM规程),对于不符合项及时提出建议和改进方案，必要时可以向高层经理汇报以求问题的解决。通过这样的途径来预防缺陷的引入，从而减少后期软件的维护成本。

SQA主要的工作活动包括制定SQA工作计划，参与阶段产物的评审，进行过程质量、功能配置及物理配置的审计等;对项目开发过程中产生的数据进行度量等等。

‍

‍

### 软件测试理论

[软件测试基础知识 + 面试理论（超详细）-CSDN博客](https://blog.csdn.net/weixin_43750377/article/details/114066222)

‍

### 什么是软件测试？

利用一定的方法对软件的质量或者使用性进行判断和评估的过程

‍

### 软件测试工程师的工作内容

1.寻找软件中的bug，并且越早发现越好

2.确认bug的可重复性以及bug产生的步骤

3.确认bug是否被解决

4.测试方法，测试计划，测试平台，测试代码，测试用例，测试文档，测试报告的确定、编写和执行。

‍

‍

### 软件开发的几个阶段

1.项目启动阶段：了解客户需求、配置相关资源

2.项目设计阶段：明确客户需求，确立软件开发、测试的方法

3.项目执行阶段：开发与测试阶段

4.项目竣工阶段：软件的上市、后期维护与技术支持

‍

‍

### 测试流程

* 需求调查：全面了解系统概况、应用领域、软件开发周期、软件开发环境、开发组织、时间安排、功能需求、性能需求、质量需求及测试要求等。根据系统概况进行项目所需的人员、时间和工作量估计以及项目报价。制定初步的项目计划。
* 测试准备：组织测试团队、培训、建立测试和管理环境等。
* 测试设计：按照测试要求进行每个测试项的测试设计，包括测试用例的设计和测试脚本的开发等。
* 测试实施：按照测试计划实施测试。
* 测试评估：根据测试的结果，出具测试评估报告。

‍

‍

### 测试用例几大要素

标识符，测试内容，输入条件，预期结果，测试环境信息，与其他测试用例的依赖关系，测试用例需要被开发、审阅、使用、维护和保存。

‍

‍

### 软件测试方法分类

1）白盒、黑盒、灰盒

2）单元测试、集成测试、确认测试、系统测试、验收测试、 回归测试、Alpha 测试、Beta 测试

3）静态测试和动态测试

‍

‍

### 测试分为哪几个阶段? 

一般来说分为5个阶段：单元测试、集成测试、确认测试、系统测试、验收测试

‍

‍

‍

### 设计测试用例的主要方法

1）等价类划分

2）边界值分析法

3）因果图法

4）场景法

‍

1-等价类划分

常见的软件测试面试题划分等价类: 等价类是指某个输入域的子集合.在该子集合中,各个输入数据对于揭露程序中的错误都是等效的.并合理地假定:测试某等价类的代表值就等于对这一类其它值的测试.因此,可以把全部输入数据合理划分为若干等价类,在每一个等价类中取一个数据作为测试的输入条件,就可以用少量代表性的测试数据.取得较好的测试结果.等价类划分可有两种不同的情况:有效等价类和无效等价类.

‍

2-边界值分析法

边界值分析方法是对等价类划分方法的补充。测试工作经验告诉我,大量的错误是发生在输入或输出范围的边界上,而不是发生在输入输出范围的内部.因此针对各种边界情况设计测试用例,可以查出更多的错误.

使用边界值分析方法设计测试用例,首先应确定边界情况.通常输入和输出等价类的边界,就是应着重测试的边界情况.应当选取正好等于,刚刚大于或刚刚小于边界的值作为测试数据,而不是选取等价类中的典型值或任意值作为测试数据.

‍

3-错误推测法

基于经验和直觉推测程序中所有可能存在的各种错误, 从而有针对性的设计测试用例的方法.

错误推测方法的基本思想: 列举出程序中所有可能有的错误和容易发生错误的特殊情况,根据他们选择测试用例-例如, 在单元测试时曾列出的许多在模块中常见的错误-以前产品测试中曾经发现的错误等, 这些就是经验的总结。还有, 输入数据和输出数据为0的情况。输入表格为空格或输入表格只有一行-这些都是容易发生错误的情况。可选择这些情况下的例子作为测试用例.

‍

4-因果图方法

前面介绍的等价类划分方法和边界值分析方法,都是着重考虑输入条件,但未考虑输入条件之间的联系, 相互组合等-考虑输入条件之间的相互组合,可能会产生一些新的情况-但要检查输入条件的组合不是一件容易的事情, 即使把所有输入条件划分成等价类,他们之间的组合情况也相当多-因此必须考虑采用一种适合于描述对于多种条件的组合,相应产生多个动作的形式来考虑设计测试用例-这就需要利用因果图(逻辑模型)-因果图方法最终生成的就是判定表-它适合于检查程序输入条件的各种组合情况.

‍

5-正交表分析法

有时候，可能因为大量的参数的组合而引起测试用例数量上的激增，同时，这些测试用例并没有明显的优先级上的差距，而测试人员又无法完成这么多数量的测试，就可以通过正交表来进行缩减一些用例，从而达到尽量少的用例覆盖尽量大的范围的可能性。

‍

6-场景分析方法

指根据用户场景来模拟用户的操作步骤，这个比较类似因果图，但是可能执行的深度和可行性更好。

‍

‍

### 做好软件测试的一些关键点

1-测试人员必须经过测试基础知识和理论的相关培训

2-测试人员必须**熟悉系统功能和业务 ? 不一定, 简单的测试不需要**

3-测试要有计划，而且测试方案要和整个项目计划协调好

4-必须实现编写测试用例，测试执行阶段必须根据测试用例进行

5-易用性，功能，分支，边界，性能等功能行和非功能性需求都要进行测试

6-对于复杂的流程一定要进行流程分支，组合条件分析，再进行等价类划分准备相关测试数据

7-测试设计的一个重要内容是要准备好具体的测试数据，清楚这个测试数据是测试那个场景或分支的。

8-个人任务平均每三个测试用例至少应该发现一个BUG，否则只能说明测试用例质量不好

9-除了每天构建的重复测试可以考虑测试自动化外，其他暂时都不要考虑去自动话

‍

‍

### 你所熟悉的软件测试类型有哪些?

‍

测试类型有：**功能测试、性能测试、界面测试**

功能测试在测试工作中占有比例最大，功能测试也叫**黑盒测试**。

‍

性能测试是通过自动化的测试工具模拟多种正常、峰值以及异常负载条件来对系统的各项性能指标进行测试。负载测试和压力测试都属于性能测试，两者可以结合进行。

‍

界面测试，界面是软件与用户交互的最直接的层，界面的好坏决定用户对软件的第一印象。

区别在于，功能测试关注产品的所有功能，要考虑到每个细节功能，每个可能存在的功能问题。性能测试主要关注产品整体的多用户并发下的稳定性和健壮性。界面测试则关注与用户体验相关内容，用户使用该产品的时候是否已用，是否易懂，是否规范(用户无意输入无效的数据，当然考虑到体验性，不能太粗鲁的弹出警告)。做某个性能测试的时候，首先它可能是个功能点，首先要保证她的功能是没有问题的，然后再考虑性能的问题。

‍

‍

### 当开发人员说不是BUG时，你如何应付?

开发人员说不是BUG，有2种情况

一是需求没有确定，所以我可以这么做，这个时候可以找来产品经理进行确认，需不需要改动。3方商量确定好后再看要不要改

二是这种情况不可能发生，所以不需要修改，这个时候，我可以先尽可能的说出是BUG的一句是什么?如果被用户发现或出了问题，会有什么不良结果?程序员可能会给你很多理由，你可以对他的解释进行反驳。如果还是不行，那我可以给这个问题提出来，跟开发经理和测试经理进行确认，如果要修改就改，如果不要修改就不改。其实有些真的不是BUG，我也只是建议的方式写进测试文档中，如果开发人员不修改也没有大问题。如果不是BUG的话，一定要坚持自己的立场，让问题得到最后的确认。

‍

‍

### bug单怎么写

‍

1. 软件版本
2. 开发的接口人员
3. 优先级
4. 严重程度
5. 属于的模块
6. 描述，需要尽量给出bug的重现步骤
7. 附件中能给出相关的日志和截图。

尽可能的去帮助开发进行bug 的定位

‍

‍

‍

### 测试人员可以做什么推动开发的质量提升呢

测试人员可以通过以下几种方式推动开发的质量提升：

1. **早期介入**：在需求分析和设计阶段就参与进来，帮助识别潜在的问题和风险。
2. **编写测试用例**：根据需求文档编写详细的测试用例，确保覆盖所有功能和边界情况。
3. **自动化测试**：使用自动化测试工具（如 Selenium、JUnit 等）编写和执行自动化测试脚本，提高测试效率和覆盖率。
4. **持续集成**：与开发团队合作，将测试集成到持续集成（CI）流程中，确保每次代码变更都经过测试验证。
5. **代码审查**：参与代码审查，帮助发现代码中的潜在问题和改进点。
6. **性能测试**：进行性能测试，评估系统在高负载下的表现，找出性能瓶颈并提出优化建议。
7. **用户反馈**：收集和分析用户反馈，帮助开发团队了解用户需求和改进产品质量。
8. **培训和沟通**：与开发团队保持良好的沟通，分享测试经验和最佳实践，提升团队整体的质量意识。

通过这些方式，测试人员可以有效地推动开发质量的提升，确保产品的稳定性和可靠性。

‍

‍

‍

### 逆等测试是什么

逆等测试（Negative Testing）是一种测试方法，旨在验证系统在异常或错误输入情况下的行为。与正向测试（Positive Testing）不同，逆等测试关注的是系统在不正常或无效输入下的反应，以确保系统能够正确处理错误情况并保持稳定性。

‍

逆等测试的常见场景

1. **无效输入**：输入无效的数据，如空值、超长字符串、非法字符等。
2. **边界条件**：测试输入数据的边界值，如最小值、最大值、超出范围的值等。
3. **异常情况**：模拟系统异常情况，如网络断开、服务器宕机等。
4. **权限问题**：测试用户在没有权限的情况下尝试执行操作。

‍

### 测试左移是什么

测试左移（Shift Left Testing）是一种测试策略，旨在将测试活动尽早地引入到软件开发生命周期的早期阶段。通过在需求分析、设计和开发阶段进行测试，可以及早发现和修复缺陷，从而提高软件质量并降低修复成本。

‍

### 测试左移的关键实践

1. **需求分析阶段的测试**：在需求分析阶段，测试人员参与需求评审，确保需求的可测试性，并编写初步的测试用例。
2. **设计阶段的测试**：在设计阶段，测试人员参与设计评审，识别潜在的设计缺陷，并编写详细的测试用例。
3. **开发阶段的测试**：在开发阶段，测试人员与开发人员紧密合作，进行单元测试、集成测试和代码审查，确保代码质量。
4. **持续集成和持续交付（CI/CD）** ：将测试集成到持续集成和持续交付流程中，确保每次代码变更都经过自动化测试验证。

通过在开发阶段进行单元测试和集成测试，可以及早发现和修复缺陷，从而提高软件质量。

‍

‍

### 双向测试是什么

双向测试（Bidirectional Testing）是一种测试方法，旨在验证系统在正向和反向操作中的一致性和正确性。它通常用于验证数据转换、数据同步和接口通信等场景，确保数据在不同方向上的处理结果一致。

‍

‍

### 测试流程的生命周期

测试流程的生命周期通常包括以下几个阶段：

1. **需求分析**：

    * 了解和分析需求，确定测试目标和范围。
    * 编写测试计划，定义测试策略和方法。
2. **测试计划**：

    * 制定详细的测试计划，包括测试资源、时间表、测试环境等。
    * 确定测试用例的优先级和测试数据。
3. **测试设计**：

    * 编写测试用例，详细描述测试步骤、预期结果等。
    * 准备测试数据和测试环境。
4. **测试执行**：

    * 按照测试计划和测试用例执行测试。
    * 记录测试结果和发现的缺陷。
5. **缺陷管理**：

    * 记录和跟踪缺陷，确保缺陷得到及时修复。
    * 重新测试修复后的缺陷，验证修复效果。
6. **测试报告**：

    * 汇总测试结果，编写测试报告。
    * 分析测试覆盖率和测试效果，提出改进建议。
7. **测试总结**：

    * 评估测试过程和测试结果，总结经验教训。
    * 更新测试文档和测试用例，为后续测试提供参考。

‍

‍

### 白盒测试有哪些

白盒测试（White-box Testing）是一种软件测试方法，测试人员需要了解被测试软件的内部结构和实现细节。白盒测试的主要类型包括：

1. **单元测试**：测试单个模块或函数的功能，确保其按预期工作。
2. **集成测试**：测试多个模块或组件之间的交互，确保它们协同工作。
3. **静态代码分析**：通过工具或手动检查代码，发现潜在的错误、代码规范问题和安全漏洞。
4. **代码覆盖率分析**：通过分析测试用例执行时覆盖的代码路径，评估测试的充分性。
5. **路径测试**：测试所有可能的执行路径，确保每条路径都被测试到。
6. **分支测试**：测试代码中的每个分支（如 if-else 语句），确保所有分支都被执行。
7. **循环测试**：测试代码中的循环结构，确保循环在各种边界条件下都能正确执行。

‍

‍

‍

## 测试驱动开发？

测试驱动开发（Test-Driven Development，简称TDD）是一种软件开发方法，其核心思想是先编写测试用例，然后编写实现代码，以通过测试用例。TDD 的主要步骤如下：

1. **编写测试用例**：根据需求编写一个失败的测试用例，测试用例应该尽可能简单，明确测试目标。
2. **运行测试**：运行测试用例，确保测试用例失败，以验证测试用例的有效性。
3. **编写实现代码**：编写最少量的代码，使测试用例通过。
4. **运行测试**：再次运行测试用例，确保测试通过。
5. **重构代码**：在确保测试通过的前提下，重构代码，提高代码质量和可维护性。
6. **重复**：重复以上步骤，逐步完善功能。

‍

## 为什么投测开

我很细心，注重细节，喜欢找bug.

我要求代码质量, 但是在开发中这可能成为累赘. 我感觉自己适合测开. 

‍

## 你觉得测试开发岗和开发岗是有什么区别？

测试开发岗和开发岗在职责和工作内容上有一些区别：

‍

### 测试开发岗

1. **主要职责**：

    * 设计和编写测试用例。
    * 开发和维护自动化测试脚本。
    * 执行测试，记录和跟踪缺陷。
    * 分析测试结果，编写测试报告。
    * 确保软件质量和稳定性。
2. **技能要求**：

    * 熟悉测试理论和方法。
    * 掌握自动化测试工具和框架（如 Selenium、JUnit、TestNG 等）。
    * 具备编程能力，通常需要掌握一到两门编程语言（如 Java、Python）。
    * 了解持续集成和持续交付（CI/CD）流程。

‍

### 开发岗

1. **主要职责**：

    * 设计和实现软件功能。
    * 编写和维护代码。
    * 进行代码审查和优化。
    * 修复软件缺陷。
    * 参与需求分析和系统设计。
2. **技能要求**：

    * 熟悉软件开发生命周期（SDLC）。
    * 掌握编程语言和开发框架（如 Java、JavaScript、Spring、React 等）。
    * 具备问题分析和解决能力。
    * 了解版本控制工具（如 Git）。

### 总结

* **测试开发岗**更侧重于软件质量保证，通过测试用例和自动化测试来发现和解决问题。
* **开发岗**更侧重于功能实现和代码编写，通过设计和实现软件功能来满足需求。

两者在工作中有一定的交集，但侧重点不同。

‍

‍

## 如何确定测试的重点和优先级？

确定测试的重点和优先级可以通过以下几个步骤进行：

1. **需求分析**：

    * 了解和分析需求，确定哪些功能是关键功能，哪些是次要功能。
    * 确定业务需求和用户需求的优先级。
2. **风险评估**：

    * 评估各个功能模块的风险，确定哪些模块可能会对系统的稳定性和安全性产生重大影响。
    * 根据风险评估结果，确定测试的重点。
3. **历史数据**：

    * 分析历史缺陷数据，找出哪些模块或功能在过去出现过较多问题。
    * 对这些高风险区域进行重点测试。
4. **用户反馈**：

    * 收集用户反馈，了解用户在使用过程中遇到的主要问题。
    * 根据用户反馈，确定测试的重点和优先级。
5. **测试覆盖率**：

    * 确保测试覆盖率高，优先测试那些尚未覆盖或覆盖率较低的功能模块。
    * 使用测试覆盖率工具来辅助确定测试的重点。
6. **资源和时间**：

    * 根据项目的资源和时间限制，合理分配测试资源，确定测试的优先级。
    * 优先测试那些对项目成功至关重要的功能。

‍

‍

## 介绍常用抓包工具以及一般抓包的流程

常用的抓包工具包括：

1. **Wireshark**：一个开源的网络协议分析工具，可以捕获和分析网络流量。
2. **Fiddler**：一个强大的HTTP调试代理工具，适用于捕获和分析HTTP/HTTPS流量。
3. **Charles**：一个HTTP代理/HTTP监视器/反向代理，适用于调试和分析HTTP/HTTPS流量。
4. **tcpdump**：一个命令行抓包工具，适用于捕获和分析网络流量。

‍

### 一般抓包的流程

1. **选择抓包工具**：根据需求选择合适的抓包工具。
2. **配置抓包工具**：配置抓包工具以捕获所需的网络流量。例如，配置代理设置、过滤规则等。
3. **启动抓包**：启动抓包工具，开始捕获网络流量。
4. **执行操作**：在被测系统上执行需要分析的操作，以生成网络流量。
5. **停止抓包**：完成操作后，停止抓包工具，保存捕获的数据。
6. **分析数据**：使用抓包工具分析捕获的数据，查找和诊断问题。

‍

### 示例

以下是使用Wireshark进行抓包的简单示例：

1. **启动Wireshark**：打开Wireshark应用程序。
2. **选择网络接口**：选择要捕获流量的网络接口（如以太网、Wi-Fi）。
3. **开始捕获**：点击“Start”按钮开始捕获网络流量。
4. **执行操作**：在被测系统上执行需要分析的操作。
5. **停止捕获**：点击“Stop”按钮停止捕获网络流量。
6. **分析数据**：在Wireshark中查看和分析捕获的数据包。

通过这些步骤，可以使用抓包工具捕获和分析网络流量，帮助诊断和解决网络问题。

‍

‍

‍

## 测试用例包含哪些要素, 如何优化?

‍

测试用例通常包含以下要素：

1. **测试用例编号**：唯一标识测试用例的编号。
2. **测试用例名称**：简要描述测试用例的名称。
3. **前置条件**：执行测试用例前需要满足的条件。
4. **测试步骤**：详细描述执行测试的步骤。
5. **预期结果**：执行测试步骤后预期的结果。
6. **实际结果**：执行测试步骤后实际的结果（执行后填写）。
7. **优先级**：测试用例的优先级（高、中、低）。
8. **测试数据**：执行测试所需的数据。
9. **备注**：其他需要说明的事项。

‍

### 示例

```plaintext
测试用例编号: TC001
测试用例名称: 登录功能测试
前置条件: 用户已注册并激活账号
测试步骤:
  1. 打开登录页面
  2. 输入有效的用户名和密码
  3. 点击登录按钮
预期结果: 用户成功登录并跳转到主页
实际结果: （执行后填写）
优先级: 高
测试数据: 用户名: testuser, 密码: testpass
备注: 无
```

‍

### 优化测试用例的方法

1. **明确和简洁**：确保测试用例描述清晰、简洁，避免歧义。
2. **覆盖全面**：确保测试用例覆盖所有功能和边界情况。
3. **可重复性**：测试用例应具有可重复性，确保每次执行结果一致。
4. **独立性**：测试用例应独立，避免相互依赖。
5. **自动化**：尽量将测试用例自动化，提高执行效率。
6. **定期审查**：定期审查和更新测试用例，确保其有效性和完整性。

‍

‍

‍

## 性能测试

‍

### 思路

性能测试是评估软件系统在特定负载条件下的表现和稳定性的一种测试方法。以下是性能测试的一些常见思路：

1. **确定测试目标**：

    * 明确性能测试的目标，例如响应时间、吞吐量、资源利用率等。
2. **选择测试工具**：

    * 选择合适的性能测试工具，如 Apache JMeter、LoadRunner、Gatling 等。
3. **设计测试场景**：

    * 根据实际使用情况设计测试场景，包括并发用户数、请求类型、数据量等。
4. **准备测试环境**：

    * 搭建与生产环境相似的测试环境，确保测试结果的可靠性。
5. **编写测试脚本**：

    * 使用测试工具编写测试脚本，模拟用户行为和负载。
6. **执行测试**：

    * 逐步增加负载，执行测试，监控系统性能指标。
7. **分析测试结果**：

    * 收集和分析测试结果，找出性能瓶颈和问题。
8. **优化和调整**：

    * 根据测试结果进行系统优化和调整，提升性能。
9. **重复测试**：

    * 重新执行测试，验证优化效果，确保性能达到预期目标。

‍

‍

### 性能测试的性能指标有哪些

性能测试的性能指标通常包括以下几个方面：

1. **响应时间**：系统对请求作出响应所需的时间。
2. **吞吐量**：单位时间内系统处理的请求数量。
3. **并发用户数**：同时访问系统的用户数量。
4. **资源利用率**：系统资源（如 CPU、内存、磁盘 I/O 等）的使用情况。
5. **错误率**：在测试过程中发生的错误请求的比例。
6. **延迟**：请求在系统中传输和处理的时间。
7. **事务处理时间**：特定事务从开始到结束所需的时间。

这些指标可以帮助评估系统在不同负载条件下的性能表现和稳定性。

‍

‍

### 性能测试里面，固定tps模式和虚拟用户模式的区别

在性能测试中，固定TPS模式和虚拟用户模式是两种不同的负载生成方式，它们的区别如下：

1. **固定TPS模式**：

    * **定义**：TPS（Transactions Per Second）模式是指在测试过程中保持每秒事务数（请求数）的恒定。
    * **特点**：这种模式下，系统会根据设定的TPS值来生成请求，确保每秒钟的请求数保持不变。
    * **适用场景**：适用于需要测试系统在特定TPS下的性能表现，例如评估系统在高并发请求下的稳定性和响应时间。
2. **虚拟用户模式**：

    * **定义**：虚拟用户模式是指在测试过程中模拟一定数量的并发用户，每个用户按照设定的行为模式进行操作。
    * **特点**：这种模式下，系统会根据设定的虚拟用户数来生成请求，用户的行为可以是随机的或预定义的。
    * **适用场景**：适用于模拟真实用户的操作场景，评估系统在不同并发用户数下的性能表现，例如登录、浏览、提交等操作。

‍

‍

## 如何保证测试用例的覆盖度

‍

1. **需求分析**：确保所有的需求都被测试用例覆盖。可以使用需求追踪矩阵（RTM）来跟踪需求和测试用例的对应关系。
2. **代码覆盖率工具**：使用代码覆盖率工具（如 JaCoCo、Cobertura）来分析测试用例对代码的覆盖情况。目标是尽量提高代码覆盖率，包括行覆盖率、分支覆盖率等。
3. **测试用例审查**：定期对测试用例进行审查，确保测试用例的完整性和有效性。可以邀请开发人员、测试人员和业务分析师参与审查。
4. **自动化测试**：尽量使用自动化测试工具来执行测试用例，提高测试效率和覆盖率。
5. **边界测试**：设计边界测试用例，确保覆盖所有可能的边界情况。
6. **异常测试**：设计异常测试用例，确保系统在异常情况下的处理。

‍

### 示例代码

以下是使用 JaCoCo 进行代码覆盖率分析的示例：

#### 1. 添加 JaCoCo 依赖

在 `pom.xml`​ 中添加 JaCoCo 插件：

```xml
<build>
    <plugins>
        <plugin>
            <groupId>org.jacoco</groupId>
            <artifactId>jacoco-maven-plugin</artifactId>
            <version>0.8.7</version>
            <executions>
                <execution>
                    <goals>
                        <goal>prepare-agent</goal>
                    </goals>
                </execution>
                <execution>
                    <id>report</id>
                    <phase>test</phase>
                    <goals>
                        <goal>report</goal>
                    </goals>
                </execution>
            </executions>
        </plugin>
    </plugins>
</build>
```

#### 2. 运行测试并生成覆盖率报告

使用以下命令运行测试并生成覆盖率报告：

```sh
mvn clean test
mvn jacoco:report
```

#### 3. 查看覆盖率报告

生成的覆盖率报告通常位于 `target/site/jacoco/index.html`​，可以在浏览器中打开查看详细的覆盖率信息。

通过这些方法，可以有效地保证测试用例的覆盖度，提高软件的质量和稳定性。

‍

‍

‍

‍

# 大块

‍

## 自动化测试

‍

### 自动化测试平台实现原理

自动化测试平台的实现原理通常包括以下几个关键部分：

1. **测试用例管理**：管理和组织测试用例，包括创建、编辑、删除和分类等功能。
2. **测试执行**：调度和执行测试用例，收集测试结果。
3. **测试报告**：生成和展示测试报告，帮助分析测试结果。
4. **持续集成**：与持续集成工具（如 Jenkins）集成，实现自动化测试的持续执行。
5. **环境管理**：管理测试环境，包括配置和维护测试环境。

‍

‍

‍

### 自动化测试框架？（Selenium，pytest）介绍下

‍

Selenium

Selenium 是一个用于 Web 应用程序自动化测试的开源工具。它支持多种浏览器（如 Chrome、Firefox、Safari 等）和多种编程语言（如 Java、Python、C# 等）。Selenium 主要包括以下组件：

1. **Selenium WebDriver**：提供跨浏览器的自动化 API，允许编写直接与浏览器交互的测试脚本。
2. **Selenium IDE**：一个集成开发环境，用于录制和回放测试脚本，适合快速创建测试用例。
3. **Selenium Grid**：允许在分布式环境中并行运行测试，支持跨多个机器和浏览器的测试执行。

‍

pytest

pytest 是一个用于 Python 的测试框架，支持简单的单元测试和复杂的功能测试。它具有以下特点：

1. **简单易用**：使用简单的函数和断言语法编写测试用例。
2. **强大的插件系统**：支持多种插件，如 pytest-cov（代码覆盖率）、pytest-xdist（并行测试）等。
3. **自动发现测试**：自动发现以 `test_`​ 开头或结尾的测试文件和测试函数。

‍

‍

‍

### Java实现ui自动化的思路

在 Java 中实现 UI 自动化测试的常见思路如下：

1. **选择自动化测试工具**：

    * 常用的工具有 Selenium、Appium 等。
2. **设置测试环境**：

    * 配置 WebDriver（如 ChromeDriver、GeckoDriver 等）。
    * 配置测试框架（如 JUnit、TestNG）。
3. **编写测试脚本**：

    * 使用 WebDriver API 编写测试脚本，模拟用户操作。
4. **执行测试**：

    * 运行测试脚本，捕获和报告测试结果。
5. **分析测试结果**：

    * 分析测试报告，找出问题并修复。

‍

‍

‍

## 压测相关

‍

‍

### 压测关键指标

在使用 Postman 等压测工具进行压力测试时，通常需要关注以下几个关键指标：

1. **响应时间（Response Time）** ：每个请求从发送到接收到响应所花费的时间。包括平均响应时间、最小响应时间、最大响应时间等。
2. **吞吐量（Throughput）** ：单位时间内处理的请求数量，通常以每秒请求数（Requests Per Second, RPS）来表示。
3. **并发用户数（Concurrent Users）** ：同时发起请求的用户数量。这个指标可以帮助评估系统在高并发情况下的表现。
4. **错误率（Error Rate）** ：请求失败的比例。包括 HTTP 错误码（如 4xx、5xx）和其他类型的错误。
5. **资源使用率（Resource Utilization）** ：服务器资源的使用情况，包括 CPU 使用率、内存使用率、磁盘 I/O 等。
6. **带宽（Bandwidth）** ：网络带宽的使用情况，通常以每秒传输的数据量（如 Mbps）来表示。
7. **延迟（Latency）** ：请求在网络中传输的时间，包括网络延迟和服务器处理延迟。

‍

‍

‍

## 如何检测、定位项目的性能瓶颈在哪

在进行压测和测试时，检测和定位项目的性能瓶颈可以通过以下步骤进行：

1. **监控系统资源**：使用监控工具来观察 CPU、内存、磁盘 I/O 和网络带宽等系统资源的使用情况。
2. **分析应用日志**：查看应用程序的日志文件，寻找异常或错误信息。 (看看提示输出, 使用/搜素)
3. **使用性能分析工具**：使用性能分析工具（如 Java 的 VisualVM、JProfiler 或 YourKit）来分析应用程序的性能。
4. **数据库监控**：监控数据库的性能，包括查询执行时间、连接数和锁等待时间等。
5. **代码分析**：检查代码中的潜在性能问题，如不必要的循环、复杂的算法和资源泄漏等。(不好)

‍

‍

‍

### 除了CPU占用率外，还有什么能判断是否到底瓶颈？

‍

> 1. **内存使用率**：高内存使用率可能导致内存不足，从而影响系统性能。
> 2. **磁盘 I/O**：高磁盘读写操作可能导致 I/O 瓶颈，影响系统响应速度。
> 3. **网络带宽**：网络带宽不足可能导致数据传输延迟，影响系统性能。
> 4. **数据库连接数**：过多的数据库连接可能导致数据库性能下降。
> 5. **线程数**：过多的线程可能导致线程调度开销增加，影响系统性能。
>
> 可以使用以下工具来监控这些指标：
>
> * **内存使用率**：`free`​、`top`​、`htop`​
> * **磁盘 I/O**：`iostat`​、`iotop`​
> * **网络带宽**：`iftop`​、`nload`​
> * **数据库连接数**：数据库自带的监控工具，如 MySQL 的 `SHOW PROCESSLIST`​
> * **线程数**：`top`​、`htop`​

‍

‍

### Jmeter调试时候怎么进行密码校验

‍

1. **添加 HTTP 请求**：在测试计划中添加一个 HTTP 请求采样器，用于发送登录请求。
2. **添加 HTTP Header Manager 信息头管理器**：在 HTTP 请求采样器中添加一个 HTTP Header Manager，用于设置请求头信息（如 Content-Type）。
3. **添加 User Defined Variables 用户定义变量**：在测试计划中添加一个 User Defined Variables 元素，用于定义用户名和密码变量。
4. **添加 Post Processor 后置处理器**：在 HTTP 请求采样器中添加一个 Post Processor（如 JSON Extractor 或 Regular Expression Extractor），用于提取响应中的认证令牌或其他验证信息。
5. **添加断言 响应断言**：在 HTTP 请求采样器中添加一个断言（如 Response Assertion），用于验证响应中是否包含预期的认证信息。

‍

‍

# 高级

‍

## 场景设计

‍

### 针对QQ这种聊天发送信息设计测试用例

设计针对QQ聊天发送信息的测试用例时，可以考虑以下几个方面：

1. **功能测试**：验证基本的发送信息功能是否正常。
2. **边界测试**：验证信息长度的边界情况。
3. **性能测试**：验证在高并发情况下发送信息的性能。
4. **异常测试**：验证在网络异常或服务器异常情况下的处理。

‍

示例测试用例

#### 功能测试

1. **发送普通文本信息**

    * **步骤**：输入普通文本信息，点击发送按钮。
    * **预期结果**：信息成功发送，接收方收到信息。
2. **发送表情**

    * **步骤**：选择一个表情，点击发送按钮。
    * **预期结果**：表情成功发送，接收方收到表情。
3. **发送图片**

    * **步骤**：选择一张图片，点击发送按钮。
    * **预期结果**：图片成功发送，接收方收到图片。

‍

#### 边界测试

1. **发送空信息**

    * **步骤**：不输入任何内容，点击发送按钮。
    * **预期结果**：提示不能发送空信息。
2. **发送超长信息**

    * **步骤**：输入超过最大长度限制的文本信息，点击发送按钮。
    * **预期结果**：提示信息过长，不能发送。

‍

#### 性能测试

1. **高并发发送信息**

    * **步骤**：模拟多个用户同时发送信息。
    * **预期结果**：系统能够正常处理高并发请求，信息发送成功率高。

‍

#### 异常测试

1. **网络断开**

    * **步骤**：在发送信息时断开网络连接。
    * **预期结果**：提示网络异常，信息发送失败。
2. **服务器异常**

    * **步骤**：在发送信息时模拟服务器异常。
    * **预期结果**：提示服务器异常，信息发送失败。

这些测试用例可以帮助全面验证QQ聊天发送信息功能的正确性和稳定性。

‍

‍

## 请描述一下在持续集成环境中实施自动化测试的经验

在持续集成（CI）环境中实施自动化测试的经验可以总结为以下几个步骤：

1. **选择CI工具**：选择适合的CI工具，如 Jenkins、GitLab CI、Travis CI 等。
2. **配置CI管道**：在 CI 工具中配置管道（Pipeline），定义各个阶段（Stages）和步骤（Steps），包括代码构建、测试、部署等。
3. **编写测试脚本**：编写自动化测试脚本，确保测试覆盖率高。可以使用 JUnit、TestNG 等测试框架进行单元测试和集成测试。
4. **集成测试工具**：将测试工具集成到 CI 管道中，确保每次代码提交后自动运行测试。
5. **报告和通知**：配置测试报告和通知机制，确保测试结果及时反馈给开发团队。

‍

### 示例

以下是一个使用 Jenkins 和 Maven 的简单示例：

#### 1. Jenkinsfile

```groovy
pipeline {
    agent any

    stages {
        stage('Build') {
            steps {
                sh 'mvn clean install'
            }
        }
        stage('Test') {
            steps {
                sh 'mvn test'
            }
        }
    }

    post {
        always {
            junit '**/target/surefire-reports/*.xml'
            mail to: 'dev-team@example.com',
                 subject: "Build \${currentBuild.fullDisplayName}",
                 body: "Build \${currentBuild.fullDisplayName} completed with status: \${currentBuild.result}"
        }
    }
}
```

#### 2. Maven配置文件 `pom.xml`​

确保在 `pom.xml`​ 中配置了必要的插件和依赖：

```xml
<project>
    <!-- ... other configurations ... -->

    <dependencies>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>4.13.2</version>
            <scope>test</scope>
        </dependency>
        <!-- other dependencies -->
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-surefire-plugin</artifactId>
                <version>2.22.2</version>
            </plugin>
            <!-- other plugins -->
        </plugins>
    </build>
</project>
```

通过这些步骤，可以在持续集成环境中有效地实施自动化测试，确保代码质量和稳定性。
